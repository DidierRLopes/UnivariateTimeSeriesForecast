{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Defines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "    Imports all modules and submodules that were necessary in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as dr\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from TimeSeriesCrossValidation import splitTrain\n",
    "from matplotlib.lines import Line2D\n",
    "from collections import OrderedDict\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, bds\n",
    "from scipy.stats import skewtest, kurtosistest, skew, kurtosis\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import het_arch, acorr_ljungbox, acorr_breusch_godfrey\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions\n",
    "    Defines helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_tuple(string):\n",
    "    try:\n",
    "        s = ast.literal_eval(str(string))\n",
    "        if type(s) == tuple:\n",
    "            return s\n",
    "        return\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute MAE over an array of different horizons\n",
    "def horizonMAE(y_true, y_pred, horizonSteps):\n",
    "    ae  = abs(y_pred - y_true.T);\n",
    "    list_MAE = list()\n",
    "    for i in horizonSteps:\n",
    "        list_MAE.append(round(np.mean(ae[0,:i]), 2))\n",
    "    return list_MAE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Mean Absolute Percentage Error\n",
    "def absolute_percentage_error(y_true, y_pred):\n",
    "    if (len(y_true[y_true == 0])):\n",
    "        print(\"Division by zero!\")\n",
    "        return None;\n",
    "    else:\n",
    "        return 100*(abs((y_pred - y_true.T) / y_true));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute MAPE over an array of different horizons\n",
    "def horizonMAPE(y_true, y_pred, horizonSteps):\n",
    "    ape = absolute_percentage_error(y_true.T, y_pred);\n",
    "    if ape is not None:\n",
    "        list_MAPE = list()\n",
    "        for i in horizonSteps:\n",
    "            list_MAPE.append(round(np.mean(ape[0,:i]), 2))\n",
    "        return list_MAPE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate combinations of p, d and q values for an ARIMA model\n",
    "def ARIMA_grid(dataset, arimaCfg, isLog):\n",
    "    df_IC = pd.DataFrame( columns=['ARIMA(p, d, q)', 'AIC', 'BIC', 'HQIC'])\n",
    "    df_IC = df_IC.set_index('ARIMA(p, d, q)')\n",
    "    dict_arimaFit  = {} \n",
    "    dict_arimaPred = {} \n",
    "    modelNum = 0;\n",
    "    totalModelNum = len(arimaCfg.p_range)*len(arimaCfg.d_range)*len(arimaCfg.q_range)\n",
    "    for p in arimaCfg.p_range:\n",
    "        for d in arimaCfg.d_range:\n",
    "            for q in arimaCfg.q_range:\n",
    "                order = (p,d,q)\n",
    "                modelNum+=1;\n",
    "                print(\"%d/%d \" % (modelNum, totalModelNum))\n",
    "\n",
    "                try:\n",
    "                    model = ARIMA(dataset, order=order);\n",
    "                    model_fit = model.fit(disp=0);\n",
    "                    \n",
    "                    if (~np.isnan(model_fit.mle_retvals.get('fopt'))):\n",
    "                        \n",
    "                        model_str = 'ARIMA' + str(order)\n",
    "                        df_IC = df_IC.append(pd.DataFrame({'AIC':model_fit.aic, 'BIC':model_fit.bic, \\\n",
    "                                                           'HQIC':model_fit.hqic}, index =[model_str]), ignore_index=False)\n",
    "\n",
    "                        if (isLog):\n",
    "                            dict_arimaFit[model_str]  = np.e**(model_fit.predict(typ='levels'));\n",
    "                            dict_arimaPred[model_str] = np.e**(model_fit.forecast(steps=stepsToForecast[-1])[0]);\n",
    "                        else:\n",
    "                            dict_arimaFit[model_str]  = model_fit.predict(typ='levels');\n",
    "                            dict_arimaPred[model_str] = model_fit.forecast(steps=stepsToForecast[-1])[0];\n",
    "                except:\n",
    "                    continue\n",
    "    return dict_arimaFit, dict_arimaPred, df_IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ARIMA_train_val_forwardChaining(sequence, minSamplesTrain, n_steps_forecast, n_steps_jump):\n",
    "    end_ix=0; i=0;\n",
    "    # Index of individual training set at each validation splits\n",
    "    Xcv, ycv = list(), list()\n",
    "        \n",
    "    # Iterate through all validation splits\n",
    "    while 1:\n",
    "        end_ix = minSamplesTrain + n_steps_jump*i;\n",
    "        \n",
    "        # Training Xcv\n",
    "        seq_xcv = sequence[0:end_ix] \n",
    "        Xcv.append(seq_xcv)\n",
    "        \n",
    "        # Training ycv\n",
    "        seq_ycv = sequence[end_ix:end_ix+n_steps_forecast]\n",
    "        ycv.append(seq_ycv)\n",
    "\n",
    "        i+=1;\n",
    "          \n",
    "        # Once val data crosses time series length return   \n",
    "        if ((minSamplesTrain + n_steps_jump*i + n_steps_forecast) > len(sequence)):\n",
    "            break\n",
    "            \n",
    "    return Xcv, ycv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Univariate Time-Series to study\n",
    "    df: Dataframe with an index and a value column\n",
    "    title: Title of data being used\n",
    "    xlab: Label of df.index\n",
    "    ylab: Label of df.values\n",
    "    seasonal_periods: The repetition cycle\n",
    "    \n",
    "    stepsToForecast: Steps to forecast out-of-sample (and in-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = Dataframe with an index and a value column\n",
    "# title = Title of data being used\n",
    "# xlab = Label of df.index\n",
    "# ylab = Label of df.values\n",
    "# seasonal_periods = The repetition cycle\n",
    "\n",
    "previousStepsToShow = 15;\n",
    "\n",
    "#stepsToForecast = [1, 3, 12]\n",
    "#df = dr.DataReader('CPIAUCSL', \"fred\", start='1947-01-01', end='2019-09-01')\n",
    "#df_train = df[['CPIAUCSL']][:-stepsToForecast[-1]].rename(columns={'CPIAUCSL': 'train'})\n",
    "#df_test = df[['CPIAUCSL']][-stepsToForecast[-1]:].rename(columns={'CPIAUCSL': 'test'})\n",
    "#title = 'CPIAUC'\n",
    "#xlab = 'Months/Year'; \n",
    "#ylab = 'CPI: Index 1982-1984=100 (Seasonally Adjusted)';\n",
    "#seasonal_periods = 12\n",
    "\n",
    "#stepsToForecast = [1, 5, 21]\n",
    "#df = pd.read_csv(\"PSI_20_Data_1992_Stooq.csv\") \n",
    "#df = pd.DataFrame(df, columns= ['Date','Close'])\n",
    "#df.set_index('Date', drop=True, inplace=True)\n",
    "#df.index = pd.to_datetime(df.index)\n",
    "#df = df.truncate(before='2002-01-01', after='2019-09-27')\n",
    "#df_train = df[['Close']][:-stepsToForecast[-1]].rename(columns={'Close': 'train'})\n",
    "#df_test = df[['Close']][-stepsToForecast[-1]:].rename(columns={'Close': 'test'})\n",
    "#title = 'PSI20: Historical Closing Prices'\n",
    "#xlab = 'Working Days/Year'; \n",
    "#ylab = 'Closing Price (Euro)';\n",
    "#seasonal_periods = 5\n",
    "\n",
    "stepsToForecast = [1, 5, 21]\n",
    "df = dr.data.get_data_yahoo('SPY', start= '1993-01-01', end='2019-09-27')\n",
    "df_train = df[['Close']][:-stepsToForecast[-1]].rename(columns={'Close': 'train'})\n",
    "df_test = df[['Close']][-stepsToForecast[-1]:].rename(columns={'Close': 'test'})\n",
    "title = 'SP500'\n",
    "xlab = 'Days/Year'; \n",
    "ylab = 'Closing Price ($)';\n",
    "seasonal_periods=5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity of the Time-Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation and its graphical representation\n",
    "    This section allows to understand the representation of the series after its transformation to achieve stationarity\n",
    "\n",
    "    Box-Cox transformations such as the logarithmic one can help to stabilise the variance of a time series. \n",
    "    Differencing can help stabilise the mean of a time series by removing changes in the level of a time series, and therefore eliminating (or reducing) trend and seasonality.\n",
    "    Note: The order Box-Cox transformation, and then, differencing, is important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.add_subplot(221)\n",
    "plt.title(title + ' (Time Series)')\n",
    "plt.plot(df_train)\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel(ylab)\n",
    "plt.grid()\n",
    "\n",
    "fig.add_subplot(222)\n",
    "plt.title('Log(' + title + ')')\n",
    "plt.plot(np.log(df_train))\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel(ylab)\n",
    "plt.grid()\n",
    "\n",
    "fig.add_subplot(223)\n",
    "plt.title('Dif(' + title + ')')\n",
    "plt.plot(df_train.diff().dropna())\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel(ylab)\n",
    "plt.grid()\n",
    "\n",
    "fig.add_subplot(224)\n",
    "plt.title('DifLog(' + title + ')')\n",
    "plt.plot(np.log(df_train).diff().dropna())\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel(ylab)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarque-Bera \n",
    "    Perform the Jarque-Bera goodness of fit test on sample data.\n",
    "    The Jarque-Bera test tests whether the sample data has the skewness and kurtosis matching a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jb, jbpval = stats.jarque_bera(df_train)\n",
    "print(\"Jarque-Bera Test for \" + title)\n",
    "print(\"Statistic: %.4f\" % jb)\n",
    "print(\"p-value: %.4f\" % jbpval)\n",
    "print(\"\")\n",
    "jb, jbpval = stats.jarque_bera(np.log(df_train))\n",
    "print(\"Jarque-Bera Test for Log(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % jb)\n",
    "print(\"p-value: %.4f\" % jbpval)\n",
    "print(\"\")\n",
    "jb, jbpval = stats.jarque_bera(df_train.diff().dropna())\n",
    "print(\"Jarque-Bera Test for Diff(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % jb)\n",
    "print(\"p-value: %.4f\" % jbpval)\n",
    "print(\"\")\n",
    "jb, jbpval = stats.jarque_bera(np.log(df_train).diff().dropna())\n",
    "print(\"Jarque-Bera Test for Diff(Log(\" + title + \"))\")\n",
    "print(\"Statistic: %.4f\" % jb)\n",
    "print(\"p-value: %.4f\" % jbpval) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov\n",
    "    ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ks, kspval = stats.kstest(df_train.values, 'norm')\n",
    "print(\"Kolmogorov-Smirnov Test\")\n",
    "print(\"Statistic: %.4f\" % ks)\n",
    "print(\"p-value: %.4f\" % kspval)  \n",
    "print(\"\")\n",
    "ks, kspval = stats.kstest(np.log(df_train), 'norm')\n",
    "print(\"Kolmogorov-Smirnov Test for Log(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % ks)\n",
    "print(\"p-value: %.4f\" % kspval)\n",
    "print(\"\")\n",
    "ks, kspval = stats.kstest(df_train.diff().dropna(), 'norm')\n",
    "print(\"Kolmogorov-Smirnov Test for Diff(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % ks)\n",
    "print(\"p-value: %.4f\" % kspval)\n",
    "print(\"\")\n",
    "ks, kspval = stats.kstest(np.log(df_train).diff().dropna(), 'norm')\n",
    "print(\"Kolmogorov-Smirnov Test for Diff(Log(\" + title + \"))\")\n",
    "print(\"Statistic: %.4f\" % ks)\n",
    "print(\"p-value: %.4f\" % kspval) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Root and Stationarity Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Augmented Dickey-Fuller test \n",
    "    ?\n",
    "    # Used to test for a unit root in a univariate process in the presence of serial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = adfuller(df_train['train'].values, regression='c')\n",
    "print(\"Augmented Dickey Fuller Test for \" + title)\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"p-value: %.4f\" % result[1])\n",
    "print(\"Used lags: %d\" % result[2])\n",
    "print(\"Num obs: %d\" % result[3])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[4].items(), key=lambda t: t[1]))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value))\n",
    "print(\"\")\n",
    "result = adfuller(np.log(df_train['train'].values), regression='c')\n",
    "print(\"Augmented Dickey Fuller Test for Log(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"p-value: %.4f\" % result[1])\n",
    "print(\"Used lags: %d\" % result[2])\n",
    "print(\"Num obs: %d\" % result[3])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[4].items(), key=lambda t: t[1]))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value))\n",
    "print(\"\")\n",
    "result = adfuller(df_train['train'].diff().dropna(), regression='c')\n",
    "print(\"Augmented Dickey Fuller Test for Diff(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"p-value: %.4f\" % result[1])\n",
    "print(\"Used lags: %d\" % result[2])\n",
    "print(\"Num obs: %d\" % result[3])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[4].items(), key=lambda t: t[1]))\n",
    "for key, value in d.items():\n",
    "    print (\"\\t%s: %.3f\" % (key, value))\n",
    "print(\"\")\n",
    "result = adfuller(np.log(df_train['train']).diff().dropna().values, regression='c')\n",
    "print(\"Augmented Dickey Fuller Test for Diff(Log(\" + title + \"))\")\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"p-value: %.4f\" % result[1])\n",
    "print(\"Used lags: %d\" % result[2])\n",
    "print(\"Num obs: %d\" % result[3])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[4].items(), key=lambda t: t[1]))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kwiatkowski-Phillips-Schmidt-Shin\n",
    "    ?\n",
    "    # Test for level or trend stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = kpss(df_train['train'].values, regression='c')\n",
    "print(\"KPSS Test for \" + title)\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[3].items(), key=lambda t: t[1], reverse=True))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value));\n",
    "print(\"\")\n",
    "result = kpss(np.log(df_train['train'].values), regression='c')\n",
    "print(\"KPSS Test for Log(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[3].items(), key=lambda t: t[1], reverse=True))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value));\n",
    "print(\"\")\n",
    "result = kpss(df_train['train'].diff().dropna(), regression='c')\n",
    "print(\"KPSS Test for Diff(\" + title + \")\")\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[3].items(), key=lambda t: t[1], reverse=True))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value));\n",
    "print(\"\")\n",
    "result = kpss(np.log(df_train['train']).diff().dropna().values, regression='c')\n",
    "print(\"KPSS Test for Diff(Log(\" + title + \"))\")\n",
    "print(\"Statistic: %.4f\" % result[0])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[3].items(), key=lambda t: t[1], reverse=True))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation plots\n",
    "    These plots are useful for identifying non-stationary time series \n",
    "\n",
    "    This also gives an idea of the order of the model by:\n",
    "        AR(p) - p from the partial autocorrelation plot\n",
    "        I(d)  - d from the number of Diffs your dataset is using\n",
    "        MA(q) - q from the autocorrelation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLags = 40\n",
    "\n",
    "fig = plt.figure(figsize=(20,15), constrained_layout=True)\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=4, figure=fig)\n",
    "\n",
    "# Auto-correlation function for original time series\n",
    "ax_acf = fig.add_subplot(spec[0, 0])\n",
    "sm.graphics.tsa.plot_acf(df_train, lags=maxLags, ax=ax_acf, title='Autocorrelations (' + title + ')')\n",
    "# Partial auto-correlation function for original time series\n",
    "ax_pacf = fig.add_subplot(spec[1, 0])\n",
    "sm.graphics.tsa.plot_pacf(df_train, lags=maxLags, ax=ax_pacf, title='Partial Autocorrelations (' + title + ')');\n",
    "\n",
    "# Auto-correlation function for time series transformed with Log\n",
    "ax_acfLog = fig.add_subplot(spec[0, 1])\n",
    "sm.graphics.tsa.plot_acf(np.log(df_train), lags=maxLags, ax=ax_acfLog, title='Autocorrelation with Log('+ title + ')')\n",
    "# Partial auto-correlation function for time series transformed with Log\n",
    "ax_pacfLog = fig.add_subplot(spec[1, 1])\n",
    "sm.graphics.tsa.plot_pacf(np.log(df_train), lags=maxLags, ax=ax_pacfLog, title='Partial Autocorrelation with Log('+ title + ')');\n",
    "\n",
    "# Auto-correlation function for time series transformed with Diff\n",
    "ax_acfDiff = fig.add_subplot(spec[2, 0])\n",
    "sm.graphics.tsa.plot_acf(df_train.diff().dropna(), lags=maxLags, ax=ax_acfDiff, title='Autocorrelation with Diff('+ title + ')')\n",
    "# Partial auto-correlation function for time series transformed with Diff\n",
    "ax_pacfDiff = fig.add_subplot(spec[3, 0])\n",
    "sm.graphics.tsa.plot_pacf(df_train.diff().dropna(), lags=maxLags, ax=ax_pacfDiff, title='Partial Autocorrelation with Diff('+ title + ')');\n",
    "\n",
    "# Auto-correlation function for time series transformed with Log\n",
    "ax_acfDiffLog = fig.add_subplot(spec[2, 1])\n",
    "sm.graphics.tsa.plot_acf(np.log(df_train).diff().dropna(), lags=maxLags, ax=ax_acfDiffLog, title='Autocorrelation with Diff(Log('+ title + '))')\n",
    "# Partial auto-correlation function for time series transformed with Log\n",
    "ax_pacfDiffLog = fig.add_subplot(spec[3, 1])\n",
    "sm.graphics.tsa.plot_pacf(np.log(df_train).diff().dropna(), lags=maxLags, ax=ax_pacfDiffLog, title='Partial Autocorrelation with Diff(Log('+ title + '))');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "    From now on, we must choose whether we go with the Log(Time-Series) or not\n",
    "    This should be done to remove stationarity of the data, so that ARIMA can work\n",
    "    In addition, if the model is multiplicative we need to use log to make it additive as ARIMA relies on that assumption\n",
    "    The previously seen differentiated data enters in the I component of the ARIMA model it will take care of differenciating for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "isLog = True\n",
    "\n",
    "if (isLog):\n",
    "    df_Train = pd.DataFrame(np.log(df_train), index = df_train.index).copy()\n",
    "else:\n",
    "    df_Train = df_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "    ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Range of ARIMA models to compute\n",
    "class arimaCfg:\n",
    "    p_range = range(4, 5) # [1,7)\n",
    "    d_range = range(1, 3) # [1,3)\n",
    "    q_range = range(3, 6) # [1,7)\n",
    "\n",
    "dict_arimaFit, dict_arimaPred, df_IC = ARIMA_grid(df_Train.values, arimaCfg, isLog)\n",
    "#dict_arimaFit, dict_arimaPred, df_IC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison based on Information Criteria\n",
    "    AIC -\n",
    "    BIC - \n",
    "    HQIC -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df_IC[['AIC']].sort_values('AIC').head().rename(columns={'AIC': 'TOP 5 AIC'}))\n",
    "print(\" \")\n",
    "print(df_IC[['BIC']].sort_values('BIC').head().rename(columns={'BIC': 'TOP 5 BIC'}))\n",
    "print(\" \")\n",
    "print(df_IC[['HQIC']].sort_values('HQIC').head().rename(columns={'HQIC': 'TOP 5 HQIC'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Models Information Criteria Comparison\n",
    "    Evaluate models based on their Information Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['ARIMA(4, 1, 3)',\n",
    "          'ARIMA(4, 1, 4)',\n",
    "          'ARIMA(4, 2, 4)']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "params = {'legend.fontsize': 15,\n",
    "          'legend.handlelength': 2}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# set width of bar\n",
    "spacing = 0.05\n",
    "barWidth = 0.025\n",
    "r = np.arange(3) - ((len(labels)/2)-1)*spacing\n",
    "\n",
    "for i in np.arange(len(labels)):\n",
    "    plt.bar(r, df_IC.loc[labels[i]].values, width=barWidth, edgecolor='white', label=labels[i])\n",
    "    r = [x + spacing for x in r]\n",
    " \n",
    "plt.xticks([r + barWidth for r in range(3)], ['AIC', 'BIC', 'HQIC'], fontsize='20')\n",
    "plt.axis((-0.5, 3.0, min(df_IC.min())-0.05*(max(df_IC.max())-min(df_IC.min())), max(df_IC.max())+0.05*(max(df_IC.max())-min(df_IC.min()))))\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Models Cross-Validation\n",
    "    ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xcv, ycv = splitTrain.split_train_variableInput(sequence = df_Train.values[-540:], \n",
    "                                                minSamplesTrain = 200, \n",
    "                                                n_steps_forecast = stepsToForecast[-1], \n",
    "                                                n_steps_jump = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = ['ARIMA(4, 2, 3)',\n",
    "          'ARIMA(4, 1, 3)',\n",
    "          'ARIMA(4, 2, 4)']\n",
    "\n",
    "dict_MAE = {} \n",
    "for model_str in labels:\n",
    "    list_conv = list()\n",
    "    list_mae = list()\n",
    "    list_mape = list()\n",
    "    print(\"%s\" % model_str);\n",
    "    for i in np.arange(len(Xcv)):\n",
    "        try:\n",
    "            model = ARIMA(Xcv[i], order=parse_tuple(model_str[5:]));\n",
    "            model_fit = model.fit(disp=0);\n",
    "\n",
    "            if (~np.isnan(model_fit.mle_retvals.get('fopt'))):\n",
    "                if (isLog):\n",
    "                    predictions_array = np.e**(model_fit.forecast(steps=stepsToForecast[-1])[0]);\n",
    "                else:\n",
    "                    predictions_array = model_fit.forecast(steps=stepsToForecast[-1])[0];\n",
    "\n",
    "                list_conv.append(i+1)\n",
    "\n",
    "                mae = horizonMAE(ycv[i], predictions_array, stepsToForecast)\n",
    "                list_mae.append(mae)\n",
    "\n",
    "                mape = horizonMAPE(ycv[i], predictions_array, stepsToForecast)\n",
    "                list_mape.append(mape)\n",
    "\n",
    "                print(\"%d/%d - Success\" % (i+1, len(Xcv)));\n",
    "            else:\n",
    "                print(\"%d/%d - No\" % (i+1, len(Xcv)));\n",
    "        except:\n",
    "            print(\"%d/%d - No\" % (i+1, len(Xcv)));\n",
    "            continue\n",
    "    print(\"\")\n",
    "\n",
    "    dict_MAE[model_str] =  {'conv': list_conv, 'mae': list_mae, 'mape': list_mape}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PRED_IX = 1\n",
    "labels = ['ARIMA(4, 2, 3)',\n",
    "          'ARIMA(4, 1, 3)',\n",
    "          'ARIMA(4, 2, 4)']\n",
    "\n",
    "plt.figure(figsize=(20,5));\n",
    "for model_str in labels:\n",
    "    plt.plot(dict_MAE[model_str]['conv'], [mae[PRED_IX-1] for mae in dict_MAE[model_str]['mae']], 'o', markersize=10)\n",
    "plt.legend(labels)\n",
    "plt.xlabel('# RUNS')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Mean Absolute Error at each Cross-Validation run')\n",
    "if (len(Xcv) > 500):\n",
    "    plt.xticks(np.arange(0, len(Xcv), 100))\n",
    "if (len(Xcv) > 250):\n",
    "    plt.xticks(np.arange(0, len(Xcv), 50))\n",
    "elif (len(Xcv) > 50):\n",
    "    plt.xticks(np.arange(0, len(Xcv), 10))\n",
    "else:\n",
    "    plt.xticks(np.arange(1,len(Xcv)+1))\n",
    "plt.xlim([0, len(Xcv)+1])\n",
    "plt.grid()\n",
    "plt.show();\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "y_bp = []\n",
    "x_bp = np.empty((0))\n",
    "for model_str in labels:\n",
    "    if (len(dict_MAE[model_str]['conv'])>0):\n",
    "        maeVals = [mae[PRED_IX-1] for mae in dict_MAE[model_str]['mae']]\n",
    "        y_bp.extend(maeVals)\n",
    "        x_bp = np.append(x_bp, np.repeat(model_str, len(maeVals)))\n",
    "        df_bp = pd.DataFrame(data={'ARIMA Model': x_bp, 'Mean Average Error': y_bp})\n",
    "bplot=sns.boxplot(y='Mean Average Error', x='ARIMA Model', data=df_bp, width=0.5) \n",
    "plt.title('Boxplot of Mean Absolute Error of Cross-Validation associated with each ARIMA model');\n",
    "plt.grid(linewidth=.3)\n",
    "plt.show();\n",
    "\n",
    "for i in np.arange(len(labels)):\n",
    "    if (len(dict_MAE[labels[i]]['conv'])>0):\n",
    "        print(labels[i])\n",
    "        print('Prediction for ' + str(stepsToForecast[PRED_IX-1]) + ' ' + xlab + ': MAE = ' \\\n",
    "              + str(round(np.mean([mae[PRED_IX-1] for mae in dict_MAE[labels[i]]['mae']]), 2)) \\\n",
    "              + ' (' + str(round(np.mean([mape[PRED_IX-1] for mape in dict_MAE[labels[i]]['mape']]), 2)) + '%)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pick you favourite's models order\n",
    "order = (4, 1, 3)\n",
    "model = ARIMA(df_Train.values, order=order)\n",
    "model_fit = model.fit(disp=0);\n",
    "df_res = pd.DataFrame({\"resid\": model_fit.resid}, index = df_Train.index[order[1]:])\n",
    "model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "labels = ['Training and testing data', 'Fitted values', 'Predicted values']\n",
    "plt.title(title + \" prediction with ARIMA\" + str(order))\n",
    "plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, df_train.values[-previousStepsToShow:], 'k', linewidth = 3 )\n",
    "plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, dict_arimaFit['ARIMA' + str(order)][-previousStepsToShow:], 'b--' , linewidth = 2)\n",
    "plt.plot(1+np.arange(stepsToForecast[-1]), dict_arimaPred['ARIMA' + str(order)], 'r--*' , linewidth = 2)\n",
    "plt.plot(1+np.arange(stepsToForecast[-1]), df_test.values, 'k-o' , linewidth = 3 )\n",
    "plt.legend(labels, loc='upper left')\n",
    "plt.grid(color='k', linestyle='--', linewidth=.2)\n",
    "plt.xlim([1-previousStepsToShow, stepsToForecast[-1]])\n",
    "plt.xticks(1+np.arange(-previousStepsToShow, stepsToForecast[-1]))\n",
    "plt.xlabel('Past and future samples')\n",
    "plt.ylabel(ylab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot model residuals\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_res.index, df_res.values)\n",
    "plt.xlabel(xlab)\n",
    "plt.title('ARIMA' + str(order) +' Residuals')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('ARIMA' + str(order) + ' Residuals (Histogram)')\n",
    "hist_res = df_res['resid'].hist(bins=50, normed=1, edgecolor='black')\n",
    "\n",
    "df_res['resid'].plot(kind='kde', linewidth=2, linestyle='--')\n",
    "#plt.text(np.std(df_res.values), hist_res.get_ylim()[1]*0.8, r'$\\mu = $'+ str(round(np.mean(df_res), 6)))\n",
    "#plt.text(np.std(df_res.values), hist_res.get_ylim()[1]*0.75, r'$\\sigma^2 = $' + str(round(np.var(df_res), 6)))\n",
    "plt.xlabel('Residuals')\n",
    "limX = np.mean(df_res.values)+5*np.std(df_res.values);\n",
    "plt.xlim((-limX, limX))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Mean: %.6f\" % np.mean(df_res))\n",
    "print (\"Variance: %.6f\" % np.var(df_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k, kpval = kurtosistest(df_res['resid'].values)\n",
    "kurtosis_val = kurtosis(df_res['resid'].values, fisher=True)\n",
    "# If Fisher’s definition is used, then 3.0 is subtracted from the result to give 0.0 for a normal distribution.\n",
    "print(\"Kurtosis Test\")\n",
    "print(\"Statistic: %.4f\" % k)\n",
    "print(\"p-value: %.4f\" % kpval)\n",
    "print(\"Kurtosis value: %.4f\" % kurtosis_val)\n",
    "print(\" \")\n",
    "\n",
    "s, spval = skewtest(df_res['resid'].values)\n",
    "skew_val = skew(df_res['resid'].values)\n",
    "print(\"Skew Test\")\n",
    "print(\"Statistic: %.4f\" % s)\n",
    "print(\"p-value: %.4f\" % spval) \n",
    "print(\"Skewness value: %.4f\" % skew_val) \n",
    "print(\" \")\n",
    "\n",
    "jb, jbpval= stats.jarque_bera(df_res['resid'].values)\n",
    "print(\"Jarque-Bera Test\")\n",
    "print(\"Statistic: %.4f\" % jb)\n",
    "print(\"p-value: %.4f\" % jbpval)\n",
    "print(\" \")\n",
    "\n",
    "ks, kspval = stats.kstest(df_res['resid'].values, 'norm')\n",
    "print(\"Kolmogorov-Smirnov Test\")\n",
    "print(\"Statistic: %.4f\" % ks)\n",
    "print(\"p-value: %.4f\" % kspval) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engle\\'s Test for Autoregressive Conditional Heteroscedasticity (ARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm, lmpval, fval, fpval = het_arch(df_res['resid'].values)\n",
    "print('Lagrange multiplier test statistic')\n",
    "print(\"LM Statistic: %.4f\" % lm)\n",
    "print(\"LM-Test p-value: %.4f\" % lmpval)\n",
    "print('')\n",
    "\n",
    "print('fstatistic for F test')\n",
    "print(\"F Statistic: %.4f\" % fval)\n",
    "print(\"F-Test p-value: %.4f\" % fpval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for No Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brock–Dechert–Scheinkman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computing BDS\n",
    "# Tests independent and identically distributed (i.i.d.) time series\n",
    "result = bds(df_res['resid'].values, max_dim=6);\n",
    "print(\"BDS Test\")\n",
    "print(\"Dim 2: z-static %.4f Prob %.4f\" % (result[0][0], result[1][0]))\n",
    "print(\"Dim 3: z-static %.4f Prob %.4f\" % (result[0][1], result[1][1]))\n",
    "print(\"Dim 4: z-static %.4f Prob %.4f\" % (result[0][2], result[1][2]))\n",
    "print(\"Dim 5: z-static %.4f Prob %.4f\" % (result[0][3], result[1][3]))\n",
    "print(\"Dim 6: z-static %.4f Prob %.4f\" % (result[0][4], result[1][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breusch-Godfrey test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm, lmpval, fval, fpval = acorr_breusch_godfrey(model_fit, nlags = max(order[0], order[2]))\n",
    "print('Lagrange multiplier test statistic')\n",
    "print(\"LM Statistic: %.4f\" % lm)\n",
    "print(\"LM-Test p-value: %.4f\" % lmpval)\n",
    "print('')\n",
    "\n",
    "print('fstatistic for F test')\n",
    "print(\"F Statistic: %.4f\" % fval)\n",
    "print(\"F-Test p-value: %.4f\" % fpval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box-Pierce test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLags = 21\n",
    "lbvalue, pvalue, bpvalue, bppvalue = acorr_ljungbox(df_res['resid'].values, lags = range(1, maxLags), boxpierce=True)\n",
    "df_boxpierce = pd.DataFrame({'lags':range(1, maxLags), 'bp statistic': bpvalue, 'p-value':bppvalue})\n",
    "print(df_boxpierce[['lags', 'bp statistic', 'p-value']].to_string(index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ljung-Box test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ljungbox = pd.DataFrame({'lags':range(1, maxLags), 'lb statistic': bpvalue, 'p-value':pvalue})\n",
    "print(df_ljungbox[['lags', 'lb statistic', 'p-value']].to_string(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qqplot(df_res['resid'].values, stats.t, fit=True, line='45')\n",
    "plt.title('QQ plot');\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "# Auto-correlation function\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.grid()\n",
    "sm.graphics.tsa.plot_acf(df_res['resid'].values, lags=maxLags, ax=ax1)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.grid()\n",
    "sm.graphics.tsa.plot_acf(df_res['resid'].values, lags=maxLags, ax=ax2, title = 'Zoom Autocorrelation')\n",
    "ax2.axis((0, maxLags, -0.2, 0.2))\n",
    "\n",
    "# Partial auto-correlation function\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.grid()\n",
    "sm.graphics.tsa.plot_pacf(df_res['resid'].values, lags=maxLags, ax=ax3);\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax4.grid()\n",
    "sm.graphics.tsa.plot_pacf(df_res['resid'].values, lags=maxLags, ax=ax4, title = 'Zoom Partial Autocorrelation')\n",
    "ax4.axis((0, maxLags, -0.2, 0.2));\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Performance Overview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['Real Closing price', \n",
    "          'ARIMA(4, 1, 3)',\n",
    "          'ARIMA(4, 2, 3)']\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.title(title + ' fitting and forecasting')\n",
    "plt.plot(1+np.arange(stepsToForecast[-1]), df_test.values, 'k-o', linewidth = 3, label='Real values')\n",
    "for i in np.arange(len(labels)-1):\n",
    "    arimaPlot = plt.plot(1+np.arange(stepsToForecast[-1]), dict_arimaPred[labels[i+1]], '--*' , linewidth = 3, label = labels[i+1] )\n",
    "    plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, dict_arimaFit[labels[i+1]][-previousStepsToShow:], '--' , linewidth = 2, color=arimaPlot[0].get_color())\n",
    "plt.legend(loc='upper left', framealpha=0.95)\n",
    "plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, df_train.values[-previousStepsToShow:], 'k', linewidth = 4 ) # label = labels[i+1]  legenda\n",
    "plt.grid(color='k', linestyle='--', linewidth=.2)\n",
    "plt.xlim([1-previousStepsToShow,+stepsToForecast[-1]])\n",
    "plt.xticks(1+np.arange(-previousStepsToShow, stepsToForecast[-1]))\n",
    "plt.xlabel('Past and future working days')\n",
    "plt.ylabel(ylab);\n",
    "plt.show()\n",
    "\n",
    "for i in np.arange(len(labels[1:])):\n",
    "    mae  = horizonMAE(df_test.values, dict_arimaPred[labels[i+1]], stepsToForecast)\n",
    "    mape = horizonMAPE(df_test.values, dict_arimaPred[labels[i+1]], stepsToForecast)\n",
    "    print(labels[i+1])\n",
    "    for i in np.arange(len(stepsToForecast)):\n",
    "        print('Prediction for ' + str(stepsToForecast[i]) + ' ' + xlab + ': MAE = ' \\\n",
    "              + str(round(mae[i], 2)) + ' (' + str(round(mape[i], 2)) + '%)' )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_arimaPred['ARIMA(4, 1, 3)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
