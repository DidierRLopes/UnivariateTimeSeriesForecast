{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Defines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas_datareader as dr\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, bds\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy.stats import skewtest, kurtosistest, skew, kurtosis, boxcox\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load detect_sum.py\n",
    "\"\"\"Cumulative sum algorithm (CUSUM) to detect abrupt changes in data.\"\"\"\n",
    "\n",
    "from __future__ import division, print_function\n",
    "import numpy as np\n",
    "\n",
    "__author__ = 'Marcos Duarte, https://github.com/demotu/BMC'\n",
    "__version__ = \"1.0.4\"\n",
    "__license__ = \"MIT\"\n",
    "\n",
    "\n",
    "def detect_cusum(x, threshold=1, drift=0, ending=False, show=True, ax=None):\n",
    "    \"\"\"Cumulative sum algorithm (CUSUM) to detect abrupt changes in data.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1D array_like\n",
    "        data.\n",
    "    threshold : positive number, optional (default = 1)\n",
    "        amplitude threshold for the change in the data.\n",
    "    drift : positive number, optional (default = 0)\n",
    "        drift term that prevents any change in the absence of change.\n",
    "    ending : bool, optional (default = False)\n",
    "        True (1) to estimate when the change ends; False (0) otherwise.\n",
    "    show : bool, optional (default = True)\n",
    "        True (1) plots data in matplotlib figure, False (0) don't plot.\n",
    "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
    "    Returns\n",
    "    -------\n",
    "    ta : 1D array_like [indi, indf], int\n",
    "        alarm time (index of when the change was detected).\n",
    "    tai : 1D array_like, int\n",
    "        index of when the change started.\n",
    "    taf : 1D array_like, int\n",
    "        index of when the change ended (if `ending` is True).\n",
    "    amp : 1D array_like, float\n",
    "        amplitude of changes (if `ending` is True).\n",
    "    Notes\n",
    "    -----\n",
    "    Tuning of the CUSUM algorithm according to Gustafsson (2000)[1]_:\n",
    "    Start with a very large `threshold`.\n",
    "    Choose `drift` to one half of the expected change, or adjust `drift` such\n",
    "    that `g` = 0 more than 50% of the time.\n",
    "    Then set the `threshold` so the required number of false alarms (this can\n",
    "    be done automatically) or delay for detection is obtained.\n",
    "    If faster detection is sought, try to decrease `drift`.\n",
    "    If fewer false alarms are wanted, try to increase `drift`.\n",
    "    If there is a subset of the change times that does not make sense,\n",
    "    try to increase `drift`.\n",
    "    Note that by default repeated sequential changes, i.e., changes that have\n",
    "    the same beginning (`tai`) are not deleted because the changes were\n",
    "    detected by the alarm (`ta`) at different instants. This is how the\n",
    "    classical CUSUM algorithm operates.\n",
    "    If you want to delete the repeated sequential changes and keep only the\n",
    "    beginning of the first sequential change, set the parameter `ending` to\n",
    "    True. In this case, the index of the ending of the change (`taf`) and the\n",
    "    amplitude of the change (or of the total amplitude for a repeated\n",
    "    sequential change) are calculated and only the first change of the repeated\n",
    "    sequential changes is kept. In this case, it is likely that `ta`, `tai`,\n",
    "    and `taf` will have less values than when `ending` was set to False.\n",
    "    See this IPython Notebook [2]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Gustafsson (2000) Adaptive Filtering and Change Detection.\n",
    "    .. [2] hhttp://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectCUSUM.ipynb\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from detect_cusum import detect_cusum\n",
    "    >>> x = np.random.randn(300)/5\n",
    "    >>> x[100:200] += np.arange(0, 4, 4/100)\n",
    "    >>> ta, tai, taf, amp = detect_cusum(x, 2, .02, True, True)\n",
    "    >>> x = np.random.randn(300)\n",
    "    >>> x[100:200] += 6\n",
    "    >>> detect_cusum(x, 4, 1.5, True, True)\n",
    "    >>> x = 2*np.sin(2*np.pi*np.arange(0, 3, .01))\n",
    "    >>> ta, tai, taf, amp = detect_cusum(x, 1, .05, True, True)\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.atleast_1d(x).astype('float64')\n",
    "    gp, gn = np.zeros(x.size), np.zeros(x.size)\n",
    "    ta, tai, taf = np.array([[], [], []], dtype=int)\n",
    "    tap, tan = 0, 0\n",
    "    amp = np.array([])\n",
    "    # Find changes (online form)\n",
    "    for i in range(1, x.size):\n",
    "        s = x[i] - x[i-1]\n",
    "        gp[i] = gp[i-1] + s - drift  # cumulative sum for + change\n",
    "        gn[i] = gn[i-1] - s - drift  # cumulative sum for - change\n",
    "        if gp[i] < 0:\n",
    "            gp[i], tap = 0, i\n",
    "        if gn[i] < 0:\n",
    "            gn[i], tan = 0, i\n",
    "        if gp[i] > threshold or gn[i] > threshold:  # change detected!\n",
    "            ta = np.append(ta, i)    # alarm index\n",
    "            tai = np.append(tai, tap if gp[i] > threshold else tan)  # start\n",
    "            gp[i], gn[i] = 0, 0      # reset alarm\n",
    "    # THE CLASSICAL CUSUM ALGORITHM ENDS HERE\n",
    "\n",
    "    # Estimation of when the change ends (offline form)\n",
    "    if tai.size and ending:\n",
    "        _, tai2, _, _ = detect_cusum(x[::-1], threshold, drift, show=False)\n",
    "        taf = x.size - tai2[::-1] - 1\n",
    "        # Eliminate repeated changes, changes that have the same beginning\n",
    "        tai, ind = np.unique(tai, return_index=True)\n",
    "        ta = ta[ind]\n",
    "        # taf = np.unique(taf, return_index=False)  # corect later\n",
    "        if tai.size != taf.size:\n",
    "            if tai.size < taf.size:\n",
    "                taf = taf[[np.argmax(taf >= i) for i in ta]]\n",
    "            else:\n",
    "                ind = [np.argmax(i >= ta[::-1])-1 for i in taf]\n",
    "                ta = ta[ind]\n",
    "                tai = tai[ind]\n",
    "        # Delete intercalated changes (the ending of the change is after\n",
    "        # the beginning of the next change)\n",
    "        ind = taf[:-1] - tai[1:] > 0\n",
    "        if ind.any():\n",
    "            ta = ta[~np.append(False, ind)]\n",
    "            tai = tai[~np.append(False, ind)]\n",
    "            taf = taf[~np.append(ind, False)]\n",
    "        # Amplitude of changes\n",
    "        amp = x[taf] - x[tai]\n",
    "\n",
    "    if show:\n",
    "        _plot(x, threshold, drift, ending, ax, ta, tai, taf, gp, gn)\n",
    "\n",
    "    return ta, tai, taf, amp\n",
    "\n",
    "\n",
    "def _plot(x, threshold, drift, ending, ax, ta, tai, taf, gp, gn):\n",
    "    \"\"\"Plot results of the detect_cusum function, see its help.\"\"\"\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "    except ImportError:\n",
    "        print('matplotlib is not available.')\n",
    "    else:\n",
    "        if ax is None:\n",
    "            _, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
    "\n",
    "        t = range(x.size)\n",
    "        ax1.plot(t, x, 'b-', lw=2)\n",
    "        if len(ta):\n",
    "            ax1.plot(tai, x[tai], '>', mfc='g', mec='g', ms=10,\n",
    "                     label='Start')\n",
    "            if ending:\n",
    "                ax1.plot(taf, x[taf], '<', mfc='g', mec='g', ms=10,\n",
    "                         label='Ending')\n",
    "            ax1.plot(ta, x[ta], 'o', mfc='r', mec='r', mew=1, ms=5,\n",
    "                     label='Alarm')\n",
    "            ax1.legend(loc='best', framealpha=.5, numpoints=1)\n",
    "        ax1.set_xlim(-.01*x.size, x.size*1.01-1)\n",
    "        ax1.set_xlabel('Data #', fontsize=14)\n",
    "        ax1.set_ylabel('Amplitude', fontsize=14)\n",
    "        ymin, ymax = x[np.isfinite(x)].min(), x[np.isfinite(x)].max()\n",
    "        yrange = ymax - ymin if ymax > ymin else 1\n",
    "        ax1.set_ylim(ymin - 0.1*yrange, ymax + 0.1*yrange)\n",
    "        ax1.set_title('Time series and detected changes ' +\n",
    "                      '(threshold= %.3g, drift= %.3g): N changes = %d'\n",
    "                      % (threshold, drift, len(tai)))\n",
    "        ax2.plot(t, gp, 'y-', label='+')\n",
    "        ax2.plot(t, gn, 'm-', label='-')\n",
    "        ax2.set_xlim(-.01*x.size, x.size*1.01-1)\n",
    "        ax2.set_xlabel('Data #', fontsize=14)\n",
    "        ax2.set_ylim(-0.01*threshold, 1.1*threshold)\n",
    "        ax2.axhline(threshold, color='r')\n",
    "        ax1.set_ylabel('Amplitude', fontsize=14)\n",
    "        ax2.set_title('Time series of the cumulative sums of ' +\n",
    "                      'positive and negative changes')\n",
    "        ax2.legend(loc='best', framealpha=.5, numpoints=1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Univariate Time-Series\n",
    "#    df: Dataframe with an index and a value column\n",
    "#    title: Title of data being used\n",
    "#    serie: Serie 'Name' \n",
    "#    xlab: Label of df.index\n",
    "#    ylab: Label of df.values\n",
    "#    seasonal_periods: The repetition cycle\n",
    "\n",
    "\n",
    "df = dr.DataReader(\"CPIAUCSL\", \"fred\", start=\"1947-01-01\", end=\"2019-09-01\")\n",
    "title = \"CPIAUCSL: All Items in U.S. City Average\"\n",
    "serie = \"CPIAUCSL\"\n",
    "xlab = \"Months/Year\"; \n",
    "ylab = \"Consumer Price Index\";\n",
    "seasonal_periods = 12\n",
    "\n",
    "#df = dr.DataReader(\"TRFVOLUSM227NFWA\", \"fred\", start=\"1947-01-01\", end=\"2019-09-01\")\n",
    "#title = \"Vehicle Miles Traveled\";\n",
    "#serie = \"VMT\"\n",
    "#xlab = \"Months/Year\";\n",
    "#ylab = \"Miles Traveled (Millions)\";\n",
    "#seasonal_periods = 12\n",
    "\n",
    "#df = pd.read_csv(\"PSI_20_Data_1992_Stooq.csv\") \n",
    "#df = pd.DataFrame(df, columns= ['Date','Close'])\n",
    "#df.set_index('Date', drop=True, inplace=True)\n",
    "#df.index = pd.to_datetime(df.index)\n",
    "#df = df.truncate(before='2002-01-01', after='2019-09-27')\n",
    "#title = 'PSI20: Historical Closing Prices'\n",
    "#serie = PSI20\n",
    "#xlab = 'Business Days/Year'; \n",
    "#ylab = 'Closing Price (Euro)';\n",
    "#seasonal_periods = 5\n",
    "\n",
    "#df = dr.data.get_data_yahoo(\"SPY\", start=\"1993-01-29\", end=\"2019-09-27\")\n",
    "#df = df[['Close']]\n",
    "#title = 'SPY: Historical Closing Prices'\n",
    "#serie = \"SPY\"\n",
    "#xlab = 'Business Days/Year'; \n",
    "#ylab = 'Closing Price (Dollar)';\n",
    "#seasonal_periods = 5\n",
    "\n",
    "# Type of model we expect: \n",
    "# 'additive' - Amplitude of the seasonal effect is the same each year\n",
    "# 'multiplicative' - Seasonal and other effects act proportionally on the series\n",
    "# Note: By applying log scale to the data you can transform a multiplicative model to an additive\n",
    "model_type = 'multiplicative' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of data (i.e. float64, integer, ...)\n",
    "# Check that the number of entries matches number of non-null elements, \n",
    "#otherwise we need to take care of the missing elements. \n",
    "# Either by replacing them with fillna() or by dropping them dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize first and last 3 samples of the time series\n",
    "# This allows to see the type of data we are dealing with (and a grasp about their range)\n",
    "df.head(3).append(pd.DataFrame([[\"..\"]], columns=df.columns)).append(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(df.describe(percentiles=[.1, .25, .5, .75, .9]))\n",
    "print(\"var    %.6f\" % np.var(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the data to have an idea of what we are looking at\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df.index, df.values, LineWidth=2)\n",
    "plt.title(title + ' (Time Series)')\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel(ylab)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram plot with depicted density and rug\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.distplot(df, \n",
    "             bins = 35, color='blue',\n",
    "             hist = True, hist_kws={'edgecolor':'black'},\n",
    "             kde = True, kde_kws={\"color\": \"black\", \"lw\": 3, \"label\": \"KDE\"},\n",
    "             # rug = True, rug_kws={'edgecolor':'orange'}\n",
    "            )\n",
    "plt.title(title + ' (Histogram with Density Curve)')\n",
    "plt.ylabel('Density')\n",
    "plt.xlabel(ylab)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Distribution Function\n",
    "cdf = df[df.columns.values[0]].value_counts().sort_index().div(len(df)).cumsum()\n",
    "cdf.plot(figsize=(20,5), LineWidth=2)\n",
    "plt.title(title + ' (Cumulative Distribution Function)')\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel(ylab)\n",
    "minVal = df.values.min()\n",
    "q25 = np.quantile(df.values, .25)\n",
    "medianVal = np.quantile(df.values, .5)\n",
    "q75 = np.quantile(df.values, .75)\n",
    "data=[(minVal, q25), (.25, .25), 'r', (q25, q25), (0, .25), 'r', \\\n",
    "      (minVal, medianVal), (.5, .5), 'r', (medianVal, medianVal), (0, .5), 'r', \\\n",
    "      (minVal, q75), (.75, .75), 'r', (q75, q75), (0, .75), 'r']\n",
    "plt.plot(*data, ls='--');\n",
    "plt.text(minVal+(q25-minVal)/2, 0.27, \"Q1\", color='r', fontweight='bold')\n",
    "plt.text(minVal+(medianVal-minVal)/2, 0.52, \"Median\", color='r', fontweight='bold')\n",
    "plt.text(minVal+(q75-minVal)/2, 0.77, \"Q3\", color='r',  fontweight='bold')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box and Whisker plot yearly\n",
    "sns.set(rc={'figure.figsize':(20,5)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "box_plot = sns.boxplot(x=df.index.year, y=df.columns.values[0], data=df);\n",
    "box_plot.set(xlabel='Year', ylabel=ylab, title= title + ' (Box-plot per Year)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box and Whisker plot monthly\n",
    "sns.set(rc={'figure.figsize':(20,5)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "box_plot = sns.boxplot(x=df.index.month, y=df.columns.values[0], data=df);\n",
    "box_plot.set(xlabel='Month', ylabel=ylab, title= title + ' (Box-plot per Month)');\n",
    "box_plot.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visually assess data stationarity through rolling mean and std\n",
    "rolling_window = 300\n",
    "rolling_mean = df.rolling(rolling_window, center=True, min_periods=1).mean() \n",
    "rolling_std  = df.rolling(rolling_window, center=True, min_periods=1).std() \n",
    "\n",
    "fig, axMean = plt.subplots(figsize=(20,5))\n",
    "\n",
    "axMean.plot(df.index, df.values, label = title, linewidth=2, color='black')\n",
    "axMean.plot(rolling_mean, linestyle='--', linewidth=3, color='blue')\n",
    "axMean.set_xlabel(xlab)\n",
    "axMean.set_ylabel('Rolling mean of ' + serie, color='blue')\n",
    "axMean.legend(['Real values','Rolling Mean'])\n",
    "axMean.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "axStd = axMean.twinx()\n",
    "axStd.plot(rolling_std, label='Rolling std', linestyle='--', color='green', linewidth=3)\n",
    "axStd.set_ylabel(ylab)\n",
    "axStd.legend(['Rolling std'])\n",
    "axStd.set_ylabel('Rolling standard deviation of ' + serie, color='green')\n",
    "axStd.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "axMean.set_title('Rolling mean and std applied to ' + title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As it should be known, a time series can typically be decomposed as:\n",
    "#Additive Time Series = Level + CyclicTrend + Residual + Seasonality \n",
    "#Multiplicative Time Series = Level*CyclicTrend*Residual*Seasonality \n",
    "\n",
    "# Therefore, we will decompose the time series assuming it is both an additive and multiplicative model\n",
    "#and we will infer in its type based on the residual fit given at the end\n",
    "\n",
    "# Seasonal decomposition using moving averages\n",
    "resultAdd = seasonal_decompose(df, model='additive',       freq=seasonal_periods)\n",
    "resultMul = seasonal_decompose(df, model='multiplicative', freq=seasonal_periods)\n",
    "# Hodrick-Prescott filter\n",
    "# See Ravn and Uhlig: http://home.uchicago.edu/~huhlig/papers/uhlig.ravn.res.2002.pdf\n",
    "lamb = 107360000000\n",
    "cycleAdd, trendAdd = sm.tsa.filters.hpfilter(resultAdd.trend[resultAdd.trend.notna().values], lamb=lamb)\n",
    "cycleMul, trendMul = sm.tsa.filters.hpfilter(resultMul.trend[resultMul.trend.notna().values], lamb=lamb)\n",
    "\n",
    "fig = plt.figure(figsize=(15,15), constrained_layout=True)\n",
    "spec = gridspec.GridSpec(ncols=4, nrows=5, figure=fig)\n",
    "\n",
    "fig.add_subplot(spec[0, :])\n",
    "plt.plot(df)\n",
    "\n",
    "plt.title(title + ' (Time-Series)')\n",
    "# Additive model\n",
    "fig.add_subplot(spec[1, :2])\n",
    "plt.plot(resultAdd.trend)\n",
    "plt.title('Additive Cyclic-Trend')\n",
    "fig.add_subplot(spec[2, 0])\n",
    "plt.plot(trendAdd)\n",
    "plt.xticks([])\n",
    "plt.title('Additive Trend component')\n",
    "fig.add_subplot(spec[2, 1])\n",
    "plt.plot(cycleAdd)\n",
    "plt.xticks([])\n",
    "plt.title('Additive Cycle component')\n",
    "fig.add_subplot(spec[3, :2])\n",
    "plt.plot(resultAdd.seasonal)\n",
    "plt.title('Additive Seasonal effect')\n",
    "fig.add_subplot(spec[4, :2])\n",
    "plt.plot(resultAdd.resid)\n",
    "plt.title('Additive Residuals')\n",
    "\n",
    "# Multiplicative model\n",
    "fig.add_subplot(spec[1, 2:])\n",
    "plt.plot(resultMul.trend)\n",
    "plt.title('Multiplicative Cyclic-Trend')\n",
    "fig.add_subplot(spec[2, 2])\n",
    "plt.plot(trendMul)\n",
    "plt.xticks([])\n",
    "plt.title('Multiplicative Trend component')\n",
    "fig.add_subplot(spec[2, 3])\n",
    "plt.plot(cycleMul)\n",
    "plt.xticks([])\n",
    "plt.title('Multiplicative Cycle component')\n",
    "fig.add_subplot(spec[3, 2:])\n",
    "plt.plot(resultMul.seasonal)\n",
    "plt.title('Multiplicative Seasonal effect')\n",
    "fig.add_subplot(spec[4, 2:])\n",
    "plt.plot(resultMul.resid)\n",
    "plt.title('Multiplicative Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time-Series Level is \" + str(round(df.mean(), 2)))\n",
    "print(\"\")\n",
    "print(\"Additive Time Series\")\n",
    "FtAdd = max(0, 1-np.var(resultAdd.resid)[0]/np.var(resultAdd.trend)[0]);\n",
    "print(\"Strenght of Trend: %.4f\" % FtAdd )\n",
    "FsAdd = max(0, 1-np.var(resultAdd.resid)[0]/np.var(resultAdd.seasonal)[0]);\n",
    "print(\"Strenght of Seasonality: %.4f\" % FsAdd )\n",
    "print(\"\")\n",
    "print(\"Multiplicative Time Series\")\n",
    "FtMul = max(0, 1-np.var(resultMul.resid)[0]/np.var(resultMul.trend)[0]);\n",
    "print(\"Strenght of Trend: %.4f\" % FtMul )\n",
    "FsMul = max(0, 1-np.var(resultMul.resid)[0]/np.var(resultMul.seasonal)[0]);\n",
    "print(\"Strenght of Seasonality: %.4f\" % FsMul )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "# The Box-Cox transformation intends to transform data to be closer to normality, \n",
    "#or tranform heteroskedastic (non constant variance) data to be closer to homoskedasticity (constant variance).\n",
    "plt.plot(df.index, stats.boxcox(df.values, lmbda=.02), label = 'Box Cox Transformation '+u'($\\lambda=0.02$)', lw=3)\n",
    "# The log transform (particular Box-Cox case) can be used where the data has a positively skewed distribution,\n",
    "#and there are a few very large values. If the latter is in the area of study,\n",
    "#the transform is likely to make variance more constant and normalize data\n",
    "plt.plot(df.index, stats.boxcox(df.values, lmbda=0), label = 'Log Transformation = Box Cox Transformation '+u'($\\lambda=0$)', lw=3)\n",
    "# The arcsine transformation will help make the variances more constant throughout \n",
    "#your study area and often makes the data appear normally distributed as well.\n",
    "plt.plot(df.index, np.arcsinh(df.values), label = 'Arcsine Transformation', lw=3)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title(title + ' (Transformations study)')\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel('Transformed ' + ylab);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plots\n",
    "maxLags = 40\n",
    "# The effect of applying Box-Cox transformation against original time series\n",
    "df_boxCox = stats.boxcox(df.values, lmbda=0)\n",
    "\n",
    "fig = plt.figure(figsize=(20,10), constrained_layout=True)\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=2, figure=fig)\n",
    "\n",
    "# Auto-correlation function for original time series\n",
    "ax_acf = fig.add_subplot(spec[0, 0])\n",
    "sm.graphics.tsa.plot_acf(df, lags=maxLags, ax=ax_acf)\n",
    "# Partial auto-correlation function for original time series\n",
    "ax_pacf = fig.add_subplot(spec[1, 0])\n",
    "sm.graphics.tsa.plot_pacf(df, lags=maxLags, ax=ax_pacf);\n",
    "\n",
    "# Auto-correlation function for time series transformed with Box-Cox\n",
    "ax_acfBoxCox = fig.add_subplot(spec[0, 1])\n",
    "sm.graphics.tsa.plot_acf(df_boxCox, lags=maxLags, ax=ax_acfBoxCox, title='Autocorrelation with Box-Cox Transformation')\n",
    "# Partial auto-correlation function for time series transformed with Box-Cox\n",
    "ax_pacfBoxCox = fig.add_subplot(spec[1, 1])\n",
    "sm.graphics.tsa.plot_pacf(df_boxCox, lags=maxLags, ax=ax_pacfBoxCox, title='Partial Autocorrelation with Box-Cox Transformation');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plot\n",
    "# Compare time series against a standard normal curve\n",
    "qqplot(df.values, stats.distributions.norm, fit=True, line='45')\n",
    "plt.title('Q-Q plot');\n",
    "plt.ylabel('Sample quantiles')\n",
    "plt.xlabel('Theoretical quantiles')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Suggestions (attention to seasonal series)\n",
    "#threshold = (max(df.values)-min(df.values))/40\n",
    "#drift = (max(df.values)-min(df.values))/80\n",
    "threshold = 230;\n",
    "drift = 115;\n",
    "\n",
    "detect_cusum(df.values, threshold, drift, True, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis \n",
    "# Measures height and sharpness of the central peak relative to that of a standard bell curve\n",
    "k, kpval = kurtosistest(df)\n",
    "kurtosis_val = kurtosis(df, fisher=True)\n",
    "print(\"Kurtosis Test for \" + serie)\n",
    "print(\"Statistic: %.4f\" % k[0])\n",
    "print(\"p-value: %.4f\" % kpval[0])\n",
    "print(\" \")\n",
    "print(\"Kurtosis value: %.4f\" % kurtosis_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness\n",
    "# Measure of the asymmetry of the probability distribution of a random variable about its mean\n",
    "s, spval = skewtest(df)\n",
    "skew_val = skew(df)\n",
    "print(\"Skew Test for \" + serie)\n",
    "print(\"Statistic: %.4f\" % s[0])\n",
    "print(\"p-value: %.4f\" % spval[0]) \n",
    "print(\" \")\n",
    "print(\"Skewness value: %.4f\" % skew_val[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jarque-Bera goodness of fit test on sample data\n",
    "# Tests if the sample data has the skewness and kurtosis matching a normal distribution\n",
    "jb, jbpval= stats.jarque_bera(df)\n",
    "print(\"Jarque-Bera Test for \" + serie)\n",
    "print(\"Statistic: %.4f\" % jb)\n",
    "print(\"p-value: %.4f\" % jbpval)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolmogorov-Smirnov Test goodness of fit test on sample data\n",
    "ks, kspval = stats.kstest(df.values, 'norm')\n",
    "print(\"Kolmogorov-Smirnov Test for \" + serie)\n",
    "print(\"Statistic: %.4f\" % ks)\n",
    "print(\"p-value: %.4f\" % kspval)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engle's Test for Autoregressive Conditional Heteroscedasticity (ARCH)\n",
    "lm, lmpval, fval, fpval = het_arch(df[df.columns.values[0]].values)\n",
    "print(\"Lagrange Mltiplier Test for \" + serie)\n",
    "print(\"Statistic: %.4f\" % lm)\n",
    "print(\"p-value: %.4f\" % lmpval)\n",
    "print(\" \")\n",
    "print(\"fstatistic for F test\")\n",
    "print(\"Statistic: %.4f\" % fval)\n",
    "print(\"p-value: %.4f\" % fpval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Augmented Dickey-Fuller test \n",
    "# Used to test for a unit root in a univariate process in the presence of serial correlation.\n",
    "#regression{‘c’,’ct’,’ctt’,’nc’} 'c' - Constant and 't'-trend order to include in regression \n",
    "    #Note: 'ct' - The data is stationary around a trend\n",
    "result = adfuller(df[df.columns.values[0]].values, regression='c')\n",
    "print(\"Augmented Dickey-Fuller Test for \" + serie)\n",
    "print(\"ADF Statistic: %.4f\" % result[0])\n",
    "print(\"p-value: %.4f\" % result[1])\n",
    "print(\"Used lags: %d\" % result[2])\n",
    "print(\"Num obs: %d\" % result[3])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[4].items(), key=lambda t: t[1]))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kwiatkowski-Phillips-Schmidt-Shin test\n",
    "# Test for level or trend stationarity\n",
    "# Note: regressionstr{‘c’, ‘ct’}\n",
    "#regressionstr{‘c’, ‘ct’} wher: \n",
    "    # ‘c’  : The data is stationary around a constant (default).\n",
    "    # ‘ct’ : The data is stationary around a trend.\n",
    "#lags{None, ‘auto’, ‘legacy’}\n",
    "    # see: https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.kpss.html\n",
    "result = kpss(df[df.columns.values[0]].values, regression='c')\n",
    "print(\"Kwiatkowski-Phillips-Schmidt-Shin Test for \" + serie)\n",
    "print(\"KPSS Statistic: %.4f\" % result[0])\n",
    "print(\"Critical Values:\")\n",
    "d = OrderedDict(sorted(result[3].items(), key=lambda t: t[1], reverse=True))\n",
    "for key, value in d.items():\n",
    "    print(\"\\t%s: %.3f\" % (key, value));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Brock Dechert and Scheinkman test\n",
    "# Tests independent and identically distributed (i.i.d.) time series\n",
    "result = bds(df[df.columns.values[0]].values, max_dim=6);\n",
    "print(\"Brock Dechert and Scheinkman Test for \" + serie)\n",
    "print(\"Dim 2: z-static %.4f Prob %.4f\" % (result[0][0], result[1][0]))\n",
    "print(\"Dim 3: z-static %.4f Prob %.4f\" % (result[0][1], result[1][1]))\n",
    "print(\"Dim 4: z-static %.4f Prob %.4f\" % (result[0][2], result[1][2]))\n",
    "print(\"Dim 5: z-static %.4f Prob %.4f\" % (result[0][3], result[1][3]))\n",
    "print(\"Dim 6: z-static %.4f Prob %.4f\" % (result[0][4], result[1][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
