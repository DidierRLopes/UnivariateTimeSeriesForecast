{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as dr\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = Dataframe with an index and a value column\n",
    "# title = Title of data being used\n",
    "# xlab = Label of df.index\n",
    "# ylab = Label of df.values\n",
    "# seasonal_periods = The repetition cycle\n",
    "\n",
    "previousStepsToShow = 15;\n",
    "\n",
    "#stepsToForecast = [1, 3, 12];\n",
    "#df = dr.DataReader('CPIAUCSL', \"fred\", start='1947-01-01', end='2019-09-01')\n",
    "#df_train = df[['CPIAUCSL']][:-stepsToForecast[-1]].rename(columns={'CPIAUCSL': 'train'})\n",
    "#df_test = df[['CPIAUCSL']][-stepsToForecast[-1]:].rename(columns={'CPIAUCSL': 'test'})\n",
    "#title = 'CPIAUC'\n",
    "# Label of df.index\n",
    "#xlab = 'Months/Year'; \n",
    "# Label of df.values\n",
    "#ylab = 'CPI: Index 1982-1984=100 (Seasonally Adjusted)';\n",
    "#seasonal_periods = 12\n",
    "\n",
    "stepsToForecast = [1, 5, 21];\n",
    "df = pd.read_csv(\"PSI_20_Data_1992_Stooq.csv\") \n",
    "df = pd.DataFrame(df, columns= ['Date','Close'])\n",
    "df.set_index('Date', drop=True, inplace=True)\n",
    "df = df.truncate(after='2019-09-28')\n",
    "df_train = df[['Close']][:-stepsToForecast[-1]].rename(columns={'Close': 'train'})\n",
    "df_test = df[['Close']][-stepsToForecast[-1]:].rename(columns={'Close': 'test'})\n",
    "title = 'PSI20: Historical Closing Prices'\n",
    "xlab = 'Working Days/Year'; \n",
    "ylab = 'Closing Price (\\x80)'.decode(\"windows-1252\");\n",
    "seasonal_periods = 5\n",
    "\n",
    "#stepsToForecast = [1, 5, 21];\n",
    "#df = dr.data.get_data_yahoo('SPY', start= '1993-01-01', end='2019-09-27')\n",
    "#df_train = df[['Close']][:-stepsToForecast[-1]].rename(columns={'Close': 'train'})\n",
    "#df_test = df[['Close']][-stepsToForecast[-1]:].rename(columns={'Close': 'test'})\n",
    "#title = 'SP500'\n",
    "#xlab = 'Days/Year'; \n",
    "#ylab = 'Closing Price ($)';\n",
    "#seasonal_periods=5;\n",
    "\n",
    "#stepsToForecast = [1, 3, 12];\n",
    "#df = dr.DataReader(\"TRFVOLUSM227NFWA\", \"fred\", start=\"1947-01-01\", end=\"2019-09-01\")\n",
    "#df_train = df[['TRFVOLUSM227NFWA']][:-stepsToForecast[-1]].rename(columns={'TRFVOLUSM227NFWA': 'train'})\n",
    "#df_test = df[['TRFVOLUSM227NFWA']][-stepsToForecast[-1]:].rename(columns={'TRFVOLUSM227NFWA': 'test'})\n",
    "#title = \"Vehicle Miles Traveled\";\n",
    "#xlab = \"Months/Year\";\n",
    "#ylab = \"Millions of Miles\";\n",
    "#seasonal_periods = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_cv_test_forwardChaining(sequence, n_steps_input, n_steps_forecast, n_steps_jump):\n",
    "    X, y, Xcv, ycv, Xtest, ytest = dict(), dict(), dict(), dict(), dict(), dict()\n",
    "    j=2; # Tracks index of CV set at each train/val/test split\n",
    "    \n",
    "    # Iterate through all train/val/test splits\n",
    "    while 1:\n",
    "        start_ix=0; end_ix=0; startCv_ix=0; endCv_ix=0; startTest_ix=0; endTest_ix=0;\n",
    "        X_it, y_it, Xcv_it, ycv_it, Xtest_it, ytest_it = list(), list(), list(), list(), list(), list()\n",
    "        i=0; # Index of individual training set at each train/val/test split\n",
    "        \n",
    "        # Iterate until index of individual training set is smaller than index of cv set\n",
    "        while (i < j):\n",
    "            ## TRAINING DATA\n",
    "            start_ix = n_steps_jump*i;\n",
    "            end_ix = start_ix + n_steps_input;\n",
    "            \n",
    "            seq_x = sequence[start_ix:end_ix] \n",
    "            X_it.append(seq_x)\n",
    "            seq_y = sequence[end_ix:end_ix+n_steps_forecast]\n",
    "            y_it.append(seq_y)\n",
    "            \n",
    "            i+=1;\n",
    "          \n",
    "        # Once test data crosses time series length return   \n",
    "        if ((((end_ix+n_steps_input)+n_steps_input)+n_steps_forecast) > (len(sequence))):\n",
    "            break\n",
    "        \n",
    "        ## CROSS-VALIDATION DATA\n",
    "        startCv_ix = end_ix;\n",
    "        endCv_ix = end_ix + n_steps_input;\n",
    "        \n",
    "        seq_xcv = sequence[startCv_ix:endCv_ix] \n",
    "        Xcv_it.append(seq_xcv)\n",
    "        seq_ycv = sequence[endCv_ix:endCv_ix+n_steps_forecast]\n",
    "        ycv_it.append(seq_ycv) \n",
    "        \n",
    "        ## TEST DATA\n",
    "        startTest_ix = endCv_ix;\n",
    "        endTest_ix = endCv_ix + n_steps_input;\n",
    "        \n",
    "        seq_xtest = sequence[startTest_ix:endTest_ix] \n",
    "        Xtest_it.append(seq_xtest)\n",
    "        seq_ytest = sequence[endTest_ix:endTest_ix+n_steps_forecast]\n",
    "        ytest_it.append(seq_ytest) \n",
    "            \n",
    "        ## Add another train/val/test split \n",
    "        X[j-2] = np.array(X_it)\n",
    "        y[j-2] = np.array(y_it)\n",
    "        Xcv[j-2] = np.array(Xcv_it)\n",
    "        ycv[j-2] = np.array(ycv_it)\n",
    "        Xtest[j-2] = np.array(Xtest_it)\n",
    "        ytest[j-2] = np.array(ytest_it)\n",
    "        \n",
    "        j+=1;\n",
    "            \n",
    "    return X, y, Xcv, ycv, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_cv_test_kFold(sequence, n_steps_input, n_steps_forecast, n_steps_jump):\n",
    "    X, y, Xcv, ycv, Xtest, ytest = dict(), dict(), dict(), dict(), dict(), dict()\n",
    "    j=2;  # Tracks index of CV set at each train/val/test split\n",
    "    theEnd = 0; # Flag to terminate function\n",
    "    \n",
    "    # Iterate until test set falls outside time series length\n",
    "    while 1:\n",
    "        start_ix=0; end_ix=0; startCv_ix=0; endCv_ix=0; startTest_ix=0; endTest_ix=0;\n",
    "        X_it, y_it, Xcv_it, ycv_it, Xtest_it, ytest_it = list(), list(), list(), list(), list(), list()\n",
    "        i=0; # Index of individual training set at each train/val/test split\n",
    "        n=0; # Number of n_steps_jump\n",
    "        \n",
    "        # Iterate through all train/val/test splits\n",
    "        while 1:\n",
    "            if (i != j): \n",
    "                ## TRAINING DATA\n",
    "                start_ix = endTest_ix + n_steps_jump*n;\n",
    "                end_ix = start_ix + n_steps_input;\n",
    "                n += 1;\n",
    "\n",
    "                # Leave train/val/test split loop once training data crosses time series length\n",
    "                if end_ix+n_steps_forecast > len(sequence):\n",
    "                    break;\n",
    "\n",
    "                seq_x = sequence[start_ix:end_ix] \n",
    "                X_it.append(seq_x)\n",
    "                seq_y = sequence[end_ix:end_ix+n_steps_forecast]\n",
    "                y_it.append(seq_y)\n",
    "            else:\n",
    "                \n",
    "                # Once test data crosses time series length return   \n",
    "                if ((((end_ix+n_steps_input)+n_steps_input)+n_steps_forecast) > (len(sequence))):\n",
    "                    theEnd = 1;\n",
    "                    break\n",
    "                    \n",
    "                n=0;\n",
    "                i+=1;\n",
    "                \n",
    "                ## CROSS-VALIDATION DATA\n",
    "                startCv_ix = end_ix;\n",
    "                endCv_ix = end_ix + n_steps_input;\n",
    "                \n",
    "                seq_xcv = sequence[startCv_ix:endCv_ix] \n",
    "                Xcv_it.append(seq_xcv)\n",
    "                seq_ycv = sequence[endCv_ix:endCv_ix+n_steps_forecast]\n",
    "                ycv_it.append(seq_ycv)\n",
    "                \n",
    "                ## TEST DATA\n",
    "                startTest_ix = endCv_ix;\n",
    "                endTest_ix = endCv_ix + n_steps_input;\n",
    "\n",
    "                seq_xtest = sequence[startTest_ix:endTest_ix] \n",
    "                Xtest_it.append(seq_xtest)\n",
    "                seq_ytest = sequence[endTest_ix:endTest_ix+n_steps_forecast]\n",
    "                ytest_it.append(seq_ytest) \n",
    "                \n",
    "            i+=1;\n",
    "        \n",
    "        # Only add a train/val/test split if the time series length has not been crossed\n",
    "        if (theEnd == 1):\n",
    "            break\n",
    "        \n",
    "        ## Add another train/val/test split \n",
    "        X[j-2] = np.array(X_it)\n",
    "        y[j-2] = np.array(y_it)\n",
    "        Xcv[j-2] = np.array(Xcv_it)\n",
    "        ycv[j-2] = np.array(ycv_it)\n",
    "        Xtest[j-2] = np.array(Xtest_it)\n",
    "        ytest[j-2] = np.array(ytest_it)\n",
    "        \n",
    "        j+=1;\n",
    "            \n",
    "    return X, y, Xcv, ycv, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_cv_test_multipleKFold(sequence, n_steps_input, n_steps_forecast, n_steps_jump):\n",
    "    X, y, Xcv, ycv, Xtest, ytest = dict(), dict(), dict(), dict(), dict(), dict()\n",
    "    \n",
    "    # Iterate through 5 train/val/test splits\n",
    "    for j in np.arange(5):\n",
    "        start_ix=0; end_ix=0; startCv_ix=0; endCv_ix=0; startTest_ix=0; endTest_ix=0;\n",
    "        X_it, y_it, Xcv_it, ycv_it, Xtest_it, ytest_it = list(), list(), list(), list(), list(), list()\n",
    "        i=0; # Index of individual training set at each train/val/test split\n",
    "        n=0; # Number of n_steps_jump\n",
    "        \n",
    "        while 1: \n",
    "            if ((i+1+j)%(5) != 0):\n",
    "                # TRAINING DATA\n",
    "                start_ix = endTest_ix + n_steps_jump*n;\n",
    "                end_ix = start_ix + n_steps_input;\n",
    "                n+=1;\n",
    "\n",
    "                # Leave train/val/test split loop if train data crosses time series length\n",
    "                if end_ix+n_steps_forecast > len(sequence):\n",
    "                    break \n",
    "\n",
    "                seq_x = sequence[start_ix:end_ix] \n",
    "                X_it.append(seq_x)\n",
    "                seq_y = sequence[end_ix:end_ix+n_steps_forecast]\n",
    "                y_it.append(seq_y)\n",
    "            else:\n",
    "                # CROSS-VALIDATION DATA\n",
    "                startCv_ix = end_ix;\n",
    "                endCv_ix = end_ix + n_steps_input;\n",
    "                \n",
    "                # Leave train/val/test split loop if val data crosses time series length  \n",
    "                if ((endCv_ix+n_steps_forecast) > len(sequence)):\n",
    "                    break\n",
    "\n",
    "                seq_xcv = sequence[startCv_ix:endCv_ix] \n",
    "                Xcv_it.append(seq_xcv)\n",
    "                seq_ycv = sequence[endCv_ix:endCv_ix+n_steps_forecast]\n",
    "                ycv_it.append(seq_ycv)\n",
    "                \n",
    "                # TEST DATA\n",
    "                startTest_ix = endCv_ix;\n",
    "                endTest_ix = endCv_ix + n_steps_input;\n",
    "\n",
    "                # Leave train/val/test split loop if test data crosses time series length  \n",
    "                if ((endTest_ix+n_steps_forecast) > len(sequence)):\n",
    "                    break\n",
    "\n",
    "                seq_xtest = sequence[startTest_ix:endTest_ix] \n",
    "                Xtest_it.append(seq_xtest)\n",
    "                seq_ytest = sequence[endTest_ix:endTest_ix+n_steps_forecast]\n",
    "                ytest_it.append(seq_ytest) \n",
    "                \n",
    "                n=0;\n",
    "                i+=1;\n",
    "                \n",
    "            i+=1;\n",
    "            \n",
    "        ## Add another train/val split     \n",
    "        X[j] = np.array(X_it)\n",
    "        y[j] = np.array(y_it)\n",
    "        Xcv[j] = np.array(Xcv_it)\n",
    "        ycv[j] = np.array(ycv_it)\n",
    "        Xtest[j] = np.array(Xtest_it)\n",
    "        ytest[j] = np.array(ytest_it)\n",
    "            \n",
    "    return X, y, Xcv, ycv, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_input, stepsToForecast, n_steps_jump):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        i = n_steps_jump*i;\n",
    "        # Descobrir o indice da ultima amostra\n",
    "        end_ix = i + n_steps_input\n",
    "        # Se tivermos chegado ao fim da serie paramos\n",
    "        if end_ix+stepsToForecast > len(sequence):\n",
    "            break\n",
    "        # Extrai training/testing data\n",
    "        seq_x = sequence[i:end_ix] \n",
    "        X.append(seq_x)\n",
    "        seq_y = sequence[end_ix:end_ix+stepsToForecast]\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Mean Absolute Percentage Error\n",
    "def printMAEpred(y_true, y_pred, horizonSteps):\n",
    "    ae  = abs(y_pred - y_true);\n",
    "    ape = 100*(abs(y_pred - y_true) / y_true);\n",
    "    for i in horizonSteps:\n",
    "        print('Prediction for ' + str(i) + ' ' + xlab + ': MAE = ' + str(round(np.mean(ae[:i]), 2)) + ' (' + str(round(np.mean(ape[:i]), 2)) + '%)'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ------- PRE PROCESSING -------\n",
    "series_input = df_train.values[-2*12*21:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "series_input = scaler.fit_transform(series_input)\n",
    "\n",
    "gamma = 0.3 #testar 0.1 - 1, mais centado\n",
    "ExpMA = 0.0 \n",
    "for i in range(series_input.size):\n",
    "    ExpMA = gamma*series_input[i] + (1-gamma)*ExpMA\n",
    "    series_input[i] = ExpMA\n",
    "\n",
    "## ------- MODEL -------\n",
    "# Select between 'MLP', 'RNN', or 'LSTM'\n",
    "NN_str = 'MLP'\n",
    "\n",
    "n_steps_input = 42\n",
    "n_steps_jump = 5\n",
    "\n",
    "train_epochs = 50\n",
    "\n",
    "model = Sequential()\n",
    "if (NN_str == 'MLP'):\n",
    "    model.add(Dense(200, activation='relu', input_dim=n_steps_input)) #podemos metre mais camadas, as que se quiser\n",
    "    model.add(Dense(stepsToForecast[-1], activation='linear'))\n",
    "    model.compile( optimizer='adam', loss='mse', metrics=['mean_absolute_percentage_error'])\n",
    "elif (NN_str == 'RNN'):\n",
    "    model.add(SimpleRNN(100, input_shape=(n_steps_input, 1), activation='relu', return_sequences=True))    \n",
    "    model.add(SimpleRNN(10, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(stepsToForecast[-1]))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mean_absolute_percentage_error'])\n",
    "else:\n",
    "    model.add(LSTM(100,input_shape=(n_steps_input, 1), dropout=0.2, activation='relu', return_sequences=True))  \n",
    "    model.add(LSTM(30, activation='relu', dropout=0.1, return_sequences=True))\n",
    "    model.add(LSTM(10, dropout=0.2, return_sequences=False))\n",
    "    model.add(Dense(stepsToForecast[-1]))\n",
    "    model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation - Select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/71\n",
      "2/71\n",
      "3/71\n",
      "4/71\n",
      "5/71\n",
      "6/71\n",
      "7/71\n",
      "8/71\n",
      "9/71\n",
      "10/71\n",
      "11/71\n",
      "12/71\n",
      "13/71\n",
      "14/71\n",
      "15/71\n",
      "16/71\n",
      "17/71\n",
      "18/71\n",
      "19/71\n",
      "20/71\n",
      "21/71\n",
      "22/71\n",
      "23/71\n",
      "24/71\n",
      "25/71\n",
      "26/71\n",
      "27/71\n",
      "28/71\n",
      "29/71\n",
      "30/71\n",
      "31/71\n",
      "32/71\n",
      "33/71\n",
      "34/71\n",
      "35/71\n",
      "36/71\n",
      "37/71\n",
      "38/71\n",
      "39/71\n",
      "40/71\n",
      "41/71\n",
      "42/71\n",
      "43/71\n",
      "44/71\n",
      "45/71\n",
      "46/71\n",
      "47/71\n",
      "48/71\n",
      "49/71\n",
      "50/71\n",
      "51/71\n",
      "52/71\n",
      "53/71\n",
      "54/71\n",
      "55/71\n",
      "56/71\n",
      "57/71\n",
      "58/71\n",
      "59/71\n",
      "60/71\n",
      "61/71\n",
      "62/71\n",
      "63/71\n",
      "64/71\n",
      "65/71\n",
      "66/71\n",
      "67/71\n",
      "68/71\n",
      "69/71\n",
      "70/71\n",
      "71/71\n"
     ]
    }
   ],
   "source": [
    "## ------- SPLIT IN TRAINING/VALIDATION DATA -------\n",
    "\n",
    "# Select one of the following cross-validation methods\n",
    "#X_train, y_train, X_cv, y_cv, X_test, y_test = split_train_cv_test_forwardChaining(series_input, n_steps_input, stepsToForecast[-1], n_steps_jump)\n",
    "X_train, y_train, X_cv, y_cv, X_test, y_test = split_train_cv_test_kFold(series_input, n_steps_input, stepsToForecast[-1], n_steps_jump)\n",
    "#X_train, y_train, X_cv, y_cv, X_test, y_test = split_train_cv_test_multipleKFold(series_input, n_steps_input, stepsToForecast[-1], n_steps_jump)\n",
    "\n",
    "dict_mae = {} \n",
    "for ix in np.arange(len(X_train)):\n",
    "    \n",
    "    print(\"%d/%d\" % (ix+1, len(X_train)));\n",
    "    \n",
    "    if (NN_str == 'MLP'):\n",
    "        X_train[ix] = np.squeeze(X_train[ix], axis=2)\n",
    "        X_cv[ix] = np.squeeze(X_cv[ix], axis=2)\n",
    "        X_test[ix] = np.squeeze(X_test[ix], axis=2)\n",
    "    y_train[ix] = np.squeeze(y_train[ix], axis=2)\n",
    "    y_cv[ix] = np.squeeze(y_cv[ix], axis=2)\n",
    "    \n",
    "    ## ------- TRAINING MODEL -------\n",
    "    model.fit(X_train[ix], y_train[ix], epochs = train_epochs, verbose = 0);\n",
    "\n",
    "    ## ------- TRAINING ERROR -------\n",
    "    y_pred_train = model.predict(X_train[ix])\n",
    "    y_pred_train_t = scaler.inverse_transform(y_pred_train)\n",
    "    y_train_t = scaler.inverse_transform(y_train[ix]) \n",
    "\n",
    "    list_mae_train = list()\n",
    "    for i in np.arange(len(y_train_t)):\n",
    "        mae_train = mean_absolute_error(y_train_t[i,:], y_pred_train_t[i,:])\n",
    "        list_mae_train.append(mae_train)\n",
    "        \n",
    "    ## ------- CROSS VALIDATION ERROR -------\n",
    "    y_pred_cv = model.predict(X_cv[ix])\n",
    "    y_pred_cv_t = scaler.inverse_transform(y_pred_cv)\n",
    "    y_cv_t = scaler.inverse_transform(y_cv[ix]) \n",
    "\n",
    "    list_mae_cv = list()\n",
    "    for i in np.arange(len(y_cv_t)):     \n",
    "        mae_cv = mean_absolute_error(y_cv_t[i,: ], y_pred_cv_t[i,:])\n",
    "        list_mae_cv.append(mae_cv)\n",
    "        \n",
    "    ## ------- TEST ERROR -------\n",
    "    y_pred_test = model.predict(X_test[ix])\n",
    "    y_pred_test_t = scaler.inverse_transform(y_pred_test)\n",
    "    y_test_t = scaler.inverse_transform(y_test[ix]) \n",
    "    \n",
    "    list_mae_test = list()\n",
    "    for i in np.arange(len(y_test_t)):     \n",
    "        mae_test = mean_absolute_error(y_test_t[i,: ], y_pred_test_t[i,:])\n",
    "        list_mae_test.append(mae_test)\n",
    "    \n",
    "    dict_mae[str(ix)] = {'train': list_mae_train, 'cv': list_mae_cv, 'test': list_mae_test}\n",
    "    \n",
    "trainMae = np.mean([np.mean(dict_mae[str(runIx)]['train']) for runIx in np.arange(len(X_train))]);\n",
    "cvMae = np.mean([np.mean(dict_mae[str(runIx)]['cv']) for runIx in np.arange(len(X_train))]);\n",
    "testMae = np.mean([np.mean(dict_mae[str(runIx)]['test']) for runIx in np.arange(len(X_train))]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assess Training / Cross-Validation / Test\n",
    "# DEBUG_LEVEL = 0 - Only shows STATS of ALL runs\n",
    "#               1 - Shows the average MAE through runs \n",
    "#               2 - Shows the MAE at each run at each train/cv/test set    \n",
    "\n",
    "DEBUG_LEVEL = 0\n",
    "\n",
    "print(\"STATS of ALL runs\")    \n",
    "print(\"Train avg MAE avg = %.4f\" % trainMae) \n",
    "print(\"Cross-Validation avg MAE avg = %.4f\" % cvMae)\n",
    "print(\"Test avg MAE avg = %.4f\" % testMae)\n",
    "\n",
    "list_train_mae = list()\n",
    "list_cv_mae = list()\n",
    "list_test_mae = list()\n",
    "for runIx in np.arange(len(X_train)):\n",
    "    if (DEBUG_LEVEL > 0):\n",
    "        print(\"\")\n",
    "        print(\"----- RUN NUMBER %d -----\" % (runIx+1))\n",
    "\n",
    "    list_train_mae.append(np.mean(dict_mae[str(runIx)]['train']))\n",
    "    if (DEBUG_LEVEL > 0):\n",
    "        print (\"Train MAE avg = %.3f\" % np.mean(dict_mae[str(runIx)]['train'])) \n",
    "        if (DEBUG_LEVEL > 1):\n",
    "            if (len(dict_mae[str(runIx)]['train'])>1):\n",
    "                print(\"Individual trains: \" + str([round(x,4) for x in dict_mae[str(runIx)]['train']]))\n",
    "    \n",
    "    list_cv_mae.append(np.mean(dict_mae[str(runIx)]['cv']))\n",
    "    if (DEBUG_LEVEL > 0):\n",
    "        print (\"Cross-Validation MAE avg = %.3f\" % np.mean(dict_mae[str(runIx)]['cv'])) \n",
    "        if (DEBUG_LEVEL > 1):\n",
    "            if (len(dict_mae[str(runIx)]['cv'])>1):\n",
    "                print(\"Individual cross-validations: \" + str([round(x,4) for x in dict_mae[str(runIx)]['cv']]))\n",
    "            \n",
    "    list_test_mae.append(np.mean(dict_mae[str(runIx)]['test']))\n",
    "    if (DEBUG_LEVEL > 0):\n",
    "        print (\"Test MAE avg = %.3f\" % np.mean(dict_mae[str(runIx)]['test'])) \n",
    "        if (DEBUG_LEVEL > 1):\n",
    "            if (len(dict_mae[str(runIx)]['test'])>1):\n",
    "                print(\"Individual tests: \" + str([round(x,4) for x in dict_mae[str(runIx)]['test']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Mean Absolute Errors of each run\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(list_train_mae, 'bo', markersize=10, label = 'Train')\n",
    "plt.plot(list_cv_mae, 'ro', markersize=10, label = 'Cross-Validation')\n",
    "plt.plot(list_test_mae, 'go', markersize=10, label = 'Test')\n",
    "plt.legend()\n",
    "plt.xlabel('# RUNS')\n",
    "plt.ylabel('Average Mean Absolute Error')\n",
    "plt.title('Average Mean Absolute Error at each run')\n",
    "plt.grid()\n",
    "\n",
    "# Plot Mean Absolute Errors of each run\n",
    "x_bp = np.concatenate((np.repeat('Train', len(list_train_mae)), \\\n",
    "                       np.repeat('Cross-validation', len(list_cv_mae)), \n",
    "                       np.repeat('Test', len(list_test_mae))), axis = 0)\n",
    "\n",
    "y_bp = np.concatenate((list_train_mae, \\\n",
    "                       list_cv_mae, \\\n",
    "                       list_test_mae), axis = 0)\n",
    "\n",
    "df_bp = pd.DataFrame(data={'Data Type': x_bp, 'Mean Average Error': y_bp})\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "bplot=sns.boxplot(y='Mean Average Error', x='Data Type', data=df_bp, width=0.5)\n",
    "bplot.artists[0].set_facecolor('blue')\n",
    "bplot.artists[1].set_facecolor('red')\n",
    "bplot.artists[2].set_facecolor('green')\n",
    "plt.title('Boxplot with average Training, Cross-Validation and Testing error');\n",
    "plt.plot([-1,0], [trainMae, trainMae],'b--', lw=2, alpha=0.5)\n",
    "plt.plot([-1,1], [cvMae, cvMae],'r--', lw=2, alpha=0.5)\n",
    "plt.plot([-1,2], [testMae, testMae],'g--', lw=2, alpha=0.5)\n",
    "plt.xlim([-1, 2.5])\n",
    "plt.text(-0.70, trainMae-1.3, 'Average: ' + str(round(trainMae,2)), fontsize=14, color='b', fontweight='bold')\n",
    "plt.text(0.30, cvMae-1.3, 'Average: ' + str(round(cvMae,2)), fontsize=14, color='r', fontweight='bold')\n",
    "plt.text(1.30, testMae-1.3, 'Average: ' + str(round(testMae,2)), fontsize=14, color='g', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = split_sequence(series_input, n_steps_input, stepsToForecast[-1], n_steps_jump)\n",
    "if (NN_str == 'MLP'):\n",
    "    X_test = np.squeeze(X_test, axis=2)\n",
    "y_test = np.squeeze(y_test, axis=2)\n",
    "\n",
    "## ------- TRAIN MODEL WITH ALL DATA-------\n",
    "model.fit(X_test, y_test, epochs = train_epochs, verbose = 0);\n",
    "\n",
    "if (NN_str == 'MLP'):\n",
    "    yhat = model.predict(series_input[-n_steps_input:].T, verbose=0)\n",
    "else:\n",
    "    yhat = model.predict(series_input[-n_steps_input:].reshape(1, n_steps_input, 1), verbose=0)\n",
    "\n",
    "#plt.plot()\n",
    "y_pred_test = yhat.tolist()\n",
    "y_pred_test = scaler.inverse_transform(y_pred_test)\n",
    "\n",
    "predictions_array = np.array(y_pred_test).flatten()\n",
    "    \n",
    "real_array = np.array(df_test.values).flatten()\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(211)\n",
    "plt.title('Real versus Predicted ' + ylab)\n",
    "plt.plot(range(0,len(real_array)+1), np.concatenate((scaler.inverse_transform(series_input[-1]), real_array), axis=0), linewidth=2)\n",
    "plt.plot(range(0,len(predictions_array)+1), np.concatenate((scaler.inverse_transform(series_input[-1]), predictions_array), axis=0), linewidth=2)\n",
    "plt.xlim([0,len(predictions_array)])\n",
    "plt.xticks(np.arange(0, len(predictions_array)+1, step=1))\n",
    "plt.grid(color='k', linestyle='--', linewidth=.5)\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel(ylab)\n",
    "plt.legend(['Real value', 'Predicted value'])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(range(0,len(real_array-predictions_array)+1), np.concatenate((np.array([0]), real_array-predictions_array), axis=0), 'g-*', linewidth=2)\n",
    "plt.xticks(np.arange(0, len(predictions_array)+1, step=1))\n",
    "plt.xlim([0,len(predictions_array)])\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel('Prediction error')\n",
    "plt.grid(color='k', linestyle='--', linewidth=.5)\n",
    "plt.show()\n",
    "\n",
    "printMAEpred(real_array, predictions_array, stepsToForecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
