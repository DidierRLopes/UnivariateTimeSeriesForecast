{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Defines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "    Imports all modules and submodules that were necessary for this study.\n",
    "    Special mention to TimeSeriesCrossValidation which was created with the purpose to be used in this thesis (https://github.com/DidierRLopes/TimeSeriesCrossValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as dr\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from TimeSeriesCrossValidation import splitTrain\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt, ExponentialSmoothing\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.stats import skewtest, kurtosistest, skew, kurtosis\n",
    "from statsmodels.stats.diagnostic import het_arch, acorr_ljungbox, acorr_breusch_godfrey\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, bds\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Univariate Time-Series to study\n",
    "    df: Dataframe with an index and a value column\n",
    "    title: Title of data being used\n",
    "    serie: Serie 'Name'\n",
    "    xlab: Label of df.index\n",
    "    ylab: Label of df.values\n",
    "    seasonal_periods: The repetition cycle\n",
    "    \n",
    "    stepsToForecast: Steps to forecast out-of-sample (and in-sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_str = ['TS (N, N)', 'TS (A, N)', 'TS (Ad, N)', 'TS (N, A)', 'TS (A, A)', 'TS (Ad, A)', 'TS (N, M)', 'TS (A, M)', 'TS (Ad, M)']\n",
    "TS_print = []\n",
    "\n",
    "previousStepsToShow = 15;\n",
    "fittedValsToShow = 50;\n",
    "\n",
    "stepsToForecast = [1, 3, 12];\n",
    "df = dr.DataReader('CPIAUCSL', \"fred\", start='1947-01-01', end='2019-09-01')\n",
    "df_train = df[['CPIAUCSL']][:-stepsToForecast[-1]].rename(columns={'CPIAUCSL': 'train'})\n",
    "df_test = df[['CPIAUCSL']][-stepsToForecast[-1]:].rename(columns={'CPIAUCSL': 'test'})\n",
    "title = \"CPIAUCSL: All Items in U.S. City Average\"\n",
    "serie = \"CPIAUCSL\"\n",
    "xlab = \"Months/Year\"; \n",
    "ylab = \"Consumer Price Index\";\n",
    "seasonal_periods = 12\n",
    "\n",
    "#stepsToForecast = [1, 3, 12];\n",
    "#df = dr.DataReader(\"TRFVOLUSM227NFWA\", \"fred\", start=\"1947-01-01\", end=\"2019-09-01\")\n",
    "#df_train = df[['TRFVOLUSM227NFWA']][:-stepsToForecast[-1]].rename(columns={'TRFVOLUSM227NFWA': 'train'})\n",
    "#df_test = df[['TRFVOLUSM227NFWA']][-stepsToForecast[-1]:].rename(columns={'TRFVOLUSM227NFWA': 'test'})\n",
    "#title = \"Vehicle Miles Traveled\";\n",
    "#serie = \"VMT\"\n",
    "#xlab = \"Months/Year\";\n",
    "#ylab = \"Miles Traveled (Millions)\";\n",
    "#seasonal_periods = 12\n",
    "\n",
    "#stepsToForecast = [1, 5, 21];\n",
    "#df = pd.read_csv(\"PSI_20_Data_1992_Stooq.csv\") \n",
    "#df = pd.DataFrame(df, columns= ['Date','Close'])\n",
    "#df.set_index('Date', drop=True, inplace=True)\n",
    "#df.index = pd.to_datetime(df.index)\n",
    "#df = df.truncate(before='2002-01-01', after='2019-09-27')\n",
    "#df_train = df[['Close']][:-stepsToForecast[-1]].rename(columns={'Close': 'train'})\n",
    "#df_test = df[['Close']][-stepsToForecast[-1]:].rename(columns={'Close': 'test'})\n",
    "#title = 'PSI20: Historical Closing Prices'\n",
    "#serie = \"PSI20\"\n",
    "#xlab = 'Business Days/Year'; \n",
    "#ylab = 'Closing Price (Euro)';\n",
    "#seasonal_periods = 5\n",
    "\n",
    "#stepsToForecast = [1, 5, 21];\n",
    "#df = dr.data.get_data_yahoo('SPY', start= '1993-01-01', end='2019-09-27')\n",
    "#df_train = df[['Close']][:-stepsToForecast[-1]].rename(columns={'Close': 'train'})\n",
    "#df_test = df[['Close']][-stepsToForecast[-1]:].rename(columns={'Close': 'test'})\n",
    "#title = 'SPY: Historical Closing Prices'\n",
    "#serie = \"SPY\"\n",
    "#xlab = 'Business Days/Year'; \n",
    "#ylab = 'Closing Price (Dollar)';\n",
    "#seasonal_periods=5;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions\n",
    "    Defines helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MAE over an array of different horizons\n",
    "def horizon_mae(y_true, y_pred, horizonSteps):\n",
    "    ae  = abs(y_pred - y_true.T);\n",
    "    list_MAE = list()\n",
    "    for i in horizonSteps:\n",
    "        list_MAE.append(round(np.mean(ae[0,:i]), 2))\n",
    "    return list_MAE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Mean Absolute Percentage Error\n",
    "def absolute_percentage_error(y_true, y_pred):\n",
    "    if (len(y_true[y_true == 0])):\n",
    "        print(\"Division by zero!\")\n",
    "        return None;\n",
    "    else:\n",
    "        return 100*(abs((y_pred - y_true.T) / y_true.T));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MAPE over an array of different horizons\n",
    "def horizon_mape(y_true, y_pred, horizonSteps):\n",
    "    ape = absolute_percentage_error(y_true, y_pred);\n",
    "    if ape is not None:\n",
    "        list_MAPE = list()\n",
    "        for i in horizonSteps:\n",
    "            list_MAPE.append(round(np.mean(ape[0,:i]), 2))\n",
    "        return list_MAPE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETS_plot(train, test, fit, forecast, title, xlab=xlab, ylab=ylab, previousStepsToShow=previousStepsToShow, stepsToForecast = stepsToForecast):\n",
    "    plt.figure(figsize=(20,7))\n",
    "    labels = ['Training and testing data', 'Fitted values', 'Predicted values']\n",
    "    plt.title(title)\n",
    "    plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, train[-previousStepsToShow:], 'k', linewidth = 3 )\n",
    "    plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, fit[-previousStepsToShow-1:-1], 'b--' , linewidth = 2 )\n",
    "    plt.plot(1+np.arange(stepsToForecast[-1]), forecast, 'r--*' , linewidth = 2 )\n",
    "    plt.plot(1+np.arange(stepsToForecast[-1]), test, 'k-o' , linewidth = 3 )\n",
    "    plt.legend(labels, loc='upper left')\n",
    "    plt.grid(color='k', linestyle='--', linewidth=.2)\n",
    "    plt.xlim([1-previousStepsToShow, stepsToForecast[-1]])\n",
    "    plt.xticks(1+np.arange(-previousStepsToShow, stepsToForecast[-1]))\n",
    "    plt.xlabel('Past and future working days')\n",
    "    plt.ylabel(ylab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETS_fit_plot(train, fit, title, xlab=xlab, ylab=ylab, fittedValsToShow=fittedValsToShow):\n",
    "    plt.figure(figsize=(20,7))\n",
    "    labels = ['Training data', 'Fitted values']\n",
    "    plt.title(title)\n",
    "    plt.plot(1+np.arange(fittedValsToShow)-fittedValsToShow, train[-fittedValsToShow:], 'k', linewidth = 3 )\n",
    "    plt.plot(1+np.arange(fittedValsToShow)-fittedValsToShow, fit[-fittedValsToShow:], 'b--' , linewidth = 2 )\n",
    "    plt.legend(labels, loc='upper left')\n",
    "    plt.grid(color='k', linestyle='--', linewidth=.2)\n",
    "    plt.xlim([1-fittedValsToShow, 0])\n",
    "    plt.xticks(1+np.arange(-fittedValsToShow, 0))\n",
    "    plt.xlabel('Fitted Values to Training Data')\n",
    "    plt.ylabel(ylab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "    Check stationarity (mean and variance) through rolling mean and standard deviation. However, ETS models do not rely on data being stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 100\n",
    "rolling_mean = df_train.rolling(rolling_window, center=True, min_periods=1).mean() \n",
    "rolling_std  = df_train.rolling(rolling_window, center=True, min_periods=1).std() \n",
    "\n",
    "fig, axMean = plt.subplots(figsize=(20,5))\n",
    "\n",
    "axMean.plot(df_train.index, df_train.values, label = df_train.columns.values[0], linewidth=2, color='black')\n",
    "axMean.plot(rolling_mean, label='Rolling mean', linestyle='--', linewidth=3, color='blue')\n",
    "axMean.set_xlabel(xlab)\n",
    "axMean.legend(['Rolling mean'], loc='best')\n",
    "axMean.set_ylabel(ylab, color='blue')\n",
    "axMean.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "axStd = axMean.twinx()\n",
    "axStd.plot(rolling_std, label='Rolling std', linestyle='--', linewidth=3, color='green')\n",
    "axStd.set_ylabel(ylab)\n",
    "axStd.legend(['Rolling std'], loc='best')\n",
    "axStd.set_ylabel('Deviation of ' + ylab, color='green')\n",
    "axStd.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "axMean.set_title('Rolling mean and std applied to ' + title)\n",
    "axMean.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "    This section will train the distinct Exponential Smoothing models and also show their fit to the Time-Series in order to understand their potential. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (N, N) - Simple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_NN = ExponentialSmoothing(df_train.values, \n",
    "                                   trend=None, \n",
    "                                   damped=False,\n",
    "                                   seasonal=None)\n",
    "TS_NN = model_TS_NN.fit(smoothing_level=None)\n",
    "\n",
    "if (TS_NN.mle_retvals.success):\n",
    "    TS_NN_forecast = TS_NN.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_NN_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (N,N) - Simple Exponential Smoothing with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_NN.params['smoothing_level'],2))\n",
    "           \n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_NN.fittedvalues, \n",
    "                     title = title)\n",
    "        \n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (A, N) - Holt’s linear method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_AN = ExponentialSmoothing(df_train.values, \n",
    "                                   trend='add', \n",
    "                                   damped=False,\n",
    "                                   seasonal=None)\n",
    "TS_AN = model_TS_AN.fit(smoothing_level=None, \n",
    "                        smoothing_slope=None)\n",
    "\n",
    "if (TS_AN.mle_retvals.success):\n",
    "    TS_AN_forecast = TS_AN.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_AN_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (A,N) - Holts linear method with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_AN.params['smoothing_level'],2)) \\\n",
    "            + r', $\\beta$' + ' = ' + str(round(TS_AN.params['smoothing_slope'],2))\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_AN.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (Ad, N) - Additive damped trend method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_AdN = ExponentialSmoothing(df_train.values, \n",
    "                                    trend='add', \n",
    "                                    damped=True,\n",
    "                                    seasonal=None)\n",
    "TS_AdN = model_TS_AdN.fit(smoothing_level=None, \n",
    "                          smoothing_slope=None, \n",
    "                          damping_slope=None)\n",
    "\n",
    "if (TS_AdN.mle_retvals.success):\n",
    "    TS_AdN_forecast = TS_AdN.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_AdN_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (Ad,N) - Additive damped trend method with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_AdN.params['smoothing_level'],2)) \\\n",
    "            + r', $\\beta$' + ' = ' + str(round(TS_AdN.params['smoothing_slope'],2)) \\\n",
    "            + r', $\\zeta$' + ' = ' + str(round(TS_AdN.params['damping_slope'],2))\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_AdN.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (N, A) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_NA = ExponentialSmoothing(df_train.values, \n",
    "                                   trend=None, \n",
    "                                   damped=False, \n",
    "                                   seasonal='add', \n",
    "                                   seasonal_periods=seasonal_periods)\n",
    "TS_NA = model_TS_NA.fit(smoothing_level=None, \n",
    "                        smoothing_seasonal=None)\n",
    "\n",
    "if (TS_NA.mle_retvals.success):\n",
    "    TS_NA_forecast = TS_NA.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_NA_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (N, A) with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_NA.params['smoothing_level'],2)) \\\n",
    "            + r', $\\gamma$' + ' = ' + str(round(TS_NA.params['smoothing_seasonal'],2)) \\\n",
    "            + ', m = ' + str(model_TS_NA.seasonal_periods);\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_NA.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (A, A) - Additive Holt-Winters method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_AA = ExponentialSmoothing(df_train.values, \n",
    "                                   trend='add', \n",
    "                                   damped=False, \n",
    "                                   seasonal='add', \n",
    "                                   seasonal_periods=seasonal_periods)\n",
    "TS_AA = model_TS_AA.fit(smoothing_level=None, \n",
    "                        smoothing_slope=None, \n",
    "                        smoothing_seasonal=None)\n",
    "\n",
    "if (TS_AA.mle_retvals.success):\n",
    "    TS_AA_forecast = TS_AA.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_AA_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (Ad, A) - Additive Holt-Winters method with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_AA.params['smoothing_level'],2)) \\\n",
    "            + r', $\\beta$' + ' = ' + str(round(TS_AA.params['smoothing_slope'],2)) \\\n",
    "            + r', $\\gamma$' + ' = ' + str(round(TS_AA.params['smoothing_seasonal'],2)) \\\n",
    "            + ', m = ' + str(model_TS_AA.seasonal_periods);\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_AA.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (Ad, A) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_AdA = ExponentialSmoothing(df_train.values, \n",
    "                                    trend='add', \n",
    "                                    damped=True, \n",
    "                                    seasonal='add', \n",
    "                                    seasonal_periods=seasonal_periods)\n",
    "TS_AdA = model_TS_AdA.fit(smoothing_level=None, \n",
    "                          smoothing_slope=None, \n",
    "                          damping_slope=None, \n",
    "                          smoothing_seasonal=None)\n",
    "\n",
    "if (TS_AdA.mle_retvals.success):\n",
    "    TS_AdA_forecast = TS_AdA.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_AdA_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (Ad, A) method with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_AdA.params['smoothing_level'],2)) \\\n",
    "            + r', $\\beta$' + ' = ' + str(round(TS_AdA.params['smoothing_slope'],2)) \\\n",
    "            + r', $\\zeta$' + ' = ' + str(round(TS_AdA.params['damping_slope'],2)) \\\n",
    "            + r', $\\gamma$' + ' = ' + str(round(TS_AdA.params['smoothing_seasonal'],2)) \\\n",
    "            + ', m = ' + str(model_TS_AA.seasonal_periods);\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_AdA.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (N, M) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_NM = ExponentialSmoothing(df_train.values, \n",
    "                                    trend=None, \n",
    "                                    damped=False, \n",
    "                                    seasonal='mul', \n",
    "                                    seasonal_periods=seasonal_periods)\n",
    "TS_NM = model_TS_NM.fit(smoothing_level=None,  \n",
    "                          smoothing_seasonal=None)\n",
    "\n",
    "if (TS_NM.mle_retvals.success):\n",
    "    TS_NM_forecast = TS_NM.forecast(stepsToForecast[-1])\n",
    "    \n",
    "    if (~np.isnan(TS_NM_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (N, M) method with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_NM.params['smoothing_level'],2)) \\\n",
    "            + r', $\\gamma$' + ' = ' + str(round(TS_NM.params['smoothing_seasonal'],2)) \\\n",
    "            + ', m = ' + str(model_TS_AA.seasonal_periods);\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_NM.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (A, M) Multiplicative Holt-Winters’ method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_AM = ExponentialSmoothing(df_train.values, \n",
    "                                    trend='add', \n",
    "                                    damped=False, \n",
    "                                    seasonal='mul', \n",
    "                                    seasonal_periods=seasonal_periods)\n",
    "TS_AM = model_TS_AM.fit(smoothing_level=None, \n",
    "                        smoothing_slope=None, \n",
    "                        smoothing_seasonal=None)\n",
    "\n",
    "if (TS_AM.mle_retvals.success):\n",
    "    TS_AM_forecast = TS_AM.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_AM_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (A, M) Multiplicative Holt-Winters method with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_AA.params['smoothing_level'],2)) \\\n",
    "            + r', $\\beta$' + ' = ' + str(round(TS_AA.params['smoothing_slope'],2)) \\\n",
    "            + r', $\\gamma$' + ' = ' + str(round(TS_AA.params['smoothing_seasonal'],2)) \\\n",
    "            + ', m = ' + str(model_TS_AA.seasonal_periods);\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_AM.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TS (Ad, M) Holt-Winters’ damped method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TS_AdM = ExponentialSmoothing(df_train.values, \n",
    "                                    trend='add', \n",
    "                                    damped=True, \n",
    "                                    seasonal='mul', \n",
    "                                    seasonal_periods=seasonal_periods)\n",
    "TS_AdM = model_TS_AdM.fit(smoothing_level=None, \n",
    "                          smoothing_slope=None, \n",
    "                          damping_slope=None, \n",
    "                          smoothing_seasonal=None)\n",
    "\n",
    "if (TS_AdM.mle_retvals.success):\n",
    "    TS_AdM_forecast = TS_AdM.forecast(stepsToForecast[-1])\n",
    "\n",
    "    if (~np.isnan(TS_AdM_forecast).any()):\n",
    "        TS_print.append(True);\n",
    "        \n",
    "        title = 'TS (Ad, M) Holt-Winters damped method with ' \\\n",
    "            + r'$\\alpha$' + ' = ' + str(round(TS_AdM.params['smoothing_level'],2)) \\\n",
    "            + r', $\\beta$' + ' = ' + str(round(TS_AdM.params['smoothing_slope'],2)) \\\n",
    "            + r', $\\zeta$' + ' = ' + str(round(TS_AdM.params['damping_slope'],2)) \\\n",
    "            + r', $\\gamma$' + ' = ' + str(round(TS_AdM.params['smoothing_seasonal'],2)) \\\n",
    "            + ', m = ' + str(model_TS_AdM.seasonal_periods);\n",
    "\n",
    "        ETS_fit_plot(train = df_train.values, \n",
    "                     fit = TS_AdM.fittedvalues, \n",
    "                     title = title)\n",
    "    else:\n",
    "        TS_print.append(False);\n",
    "        print ('RuntimeWarning: invalid value encountered in double_scalars.')\n",
    "else:\n",
    "    TS_print.append(False);\n",
    "    print ('ConvergenceWarning: Optimization failed to converge.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "    This section will show Akaike Information Criteria (AIC) and Bayesian Information Criteria (BIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "params = {'legend.fontsize': 15,\n",
    "          'legend.handlelength': 2}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "TS = [TS_NN, TS_AN, TS_AdN, TS_NA, TS_AA, TS_AdA, TS_NM, TS_AM, TS_AdM]\n",
    "\n",
    "spacing = 0.05\n",
    "barWidth = 0.1\n",
    "r = np.arange(len(TS)) - (len(TS)/2)*spacing\n",
    "\n",
    "plt.subplot(211)\n",
    "TS_val = []\n",
    "for i in np.arange(len(TS)):\n",
    "    if(TS_print[i]):\n",
    "        plt.bar(r[i], TS[i].aic,  width=barWidth, edgecolor='white', label=TS_str[i])\n",
    "        TS_val.append(TS[i].aic)\n",
    "plt.axis((r[0]-.3, r[8]+.3, min(TS_val)-0.1*(max(TS_val)-min(TS_val)), max(TS_val)+0.1*(max(TS_val)-min(TS_val))))\n",
    "plt.xticks(r, TS_str, fontsize='16')\n",
    "plt.title('Aikake Information Criteria for TS models (that achieved convergence)')\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(212)\n",
    "TS_val = []\n",
    "for i in np.arange(len(TS)):\n",
    "    if(TS_print[i]):\n",
    "        plt.bar(r[i], TS[i].bic,  width=barWidth, edgecolor='white', label=TS_str[i])\n",
    "        TS_val.append(TS[i].bic)\n",
    "plt.axis((r[0]-.3, r[8]+.3, min(TS_val)-0.1*(max(TS_val)-min(TS_val)), max(TS_val)+0.1*(max(TS_val)-min(TS_val))))\n",
    "plt.xticks(r, TS_str, fontsize='16')\n",
    "plt.title('Bayesian Information Criteria for TS models (that achieved convergence)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "    The previous Model Training section and the fitted values plot allows to understand which model is likely to perform better. The previous Model Selection section allows to understand which models achieved convergence. \n",
    "    This section will exploit the residuals obtained on one of the selected model, and allows to \"validate\" our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick you favourite's models\n",
    "TS_model = 'TS (Ad, N)'\n",
    "TS_model_forecast = TS_AdM_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model residuals\n",
    "model_fit = TS[TS_str.index(TS_model)]\n",
    "df_res = pd.DataFrame({\"resid\": model_fit.resid}, index=df_train.index)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_res.index, df_res.values)\n",
    "plt.xlabel(xlab)\n",
    "plt.title(TS_model +' Residuals')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.title(TS_model + ' Residuals (Histogram)')\n",
    "hist_res = df_res['resid'].hist(bins=50, normed=1, edgecolor='black')\n",
    "df_res['resid'].plot(kind='kde', linewidth=2, linestyle='--')\n",
    "#plt.text(np.std(df_res.values), hist_res.get_ylim()[1]*0.8, r'$\\mu = $'+ str(round(np.mean(df_res), 6)))\n",
    "#plt.text(np.std(df_res.values), hist_res.get_ylim()[1]*0.75, r'$\\sigma^2 = $' + str(round(np.var(df_res), 6)))\n",
    "plt.xlabel('Residuals')\n",
    "limX = np.mean(df_res.values)+5*np.std(df_res.values);\n",
    "plt.xlim((-limX, limX))\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print (\"Mean: %.6f\" % np.mean(df_res))\n",
    "print (\"Variance: %.6f\" % np.var(df_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurtosis and Kurtosis Test\n",
    "    Compute the kurtosis (Fisher or Pearson) of a dataset.\n",
    "    Kurtosis is the fourth central moment divided by the square of the variance. If Fisher's definition is used, then 3.0 is subtracted from the result to give 0.0 for a normal distribution. If bias is False then the kurtosis is calculated using k statistics to eliminate bias coming from biased moment estimators\n",
    "\n",
    "    Test whether a dataset has normal kurtosis.\n",
    "    This function tests the null hypothesis that the kurtosis of the population from which the sample was drawn is that of the normal distribution: kurtosis = 3(n-1)/(n+1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, kpval = kurtosistest(df_res['resid'].values)\n",
    "kurtosis_val = kurtosis(df_res['resid'].values, fisher=True)\n",
    "# If Fisher’s definition is used, then 3.0 is subtracted from the result to give 0.0 for a normal distribution.\n",
    "print(\"Kurtosis Test\")\n",
    "print(\"Statistic: %.4f\" % k)\n",
    "print(\"p-value: %.4f\" % kpval)\n",
    "print(\"Kurtosis value: %.4f\" % kurtosis_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew and Skewness Test\n",
    "    Compute the skewness of a data set.\n",
    "    For normally distributed data, the skewness should be about 0. For unimodal continuous distributions, a skewness value > 0 means that there is more weight in the right tail of the distribution. The function `skewtest` can be used to determine if the skewness value is close enough to 0, statistically speaking.\n",
    "\n",
    "    Test whether the skew is different from the normal distribution.\n",
    "    This function tests the null hypothesis that the skewness of the population that the sample was drawn from is the same as that of a corresponding normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, spval = skewtest(df_res['resid'].values)\n",
    "skew_val = skew(df_res['resid'].values)\n",
    "print(\"Skew Test\")\n",
    "print(\"Statistic: %.4f\" % s)\n",
    "print(\"p-value: %.4f\" % spval) \n",
    "print(\"Skewness value: %.4f\" % skew_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarque-Bera test\n",
    "    Perform the Jarque-Bera goodness of fit test on sample data.\n",
    "    The Jarque-Bera test tests whether the sample data has the skewness and kurtosis matching a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jb, jbpval= stats.jarque_bera(df_res['resid'].values)\n",
    "print(\"Jarque-Bera Test\")\n",
    "print(\"Statistic: %.4f\" % jb)\n",
    "print(\"p-value: %.4f\" % jbpval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov test\n",
    "    Perform the Kolmogorov-Smirnov test for goodness of fit.\n",
    "    This performs a test of the distribution G(x) of an observed random variable against a given distribution F(x). Under the null hypothesis the two distributions are identical, G(x)=F(x). The alternative hypothesis can be either 'two-sided' (default), 'less' or 'greater'. The KS test is only valid for continuous distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks, kspval = stats.kstest(df_res['resid'].values, 'norm')\n",
    "print(\"Kolmogorov-Smirnov Test\")\n",
    "print(\"Statistic: %.4f\" % ks)\n",
    "print(\"p-value: %.4f\" % kspval) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engle's Test for Autoregressive Conditional Heteroscedasticity (ARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm, lmpval, fval, fpval = het_arch(df_res['resid'].values)\n",
    "print('Lagrange multiplier test statistic')\n",
    "print(\"LM Statistic: %.4f\" % lm)\n",
    "print(\"LM-Test p-value: %.4f\" % lmpval)\n",
    "print('')\n",
    "print('fstatistic for F test')\n",
    "print(\"F Statistic: %.4f\" % fval)\n",
    "print(\"F-Test p-value: %.4f\" % fpval)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for No Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brock–Dechert–Scheinkman test\n",
    "    Calculate the BDS test statistic for independence of a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing BDS\n",
    "# Tests independent and identically distributed (i.i.d.) time series\n",
    "result = bds(df_res['resid'].values, max_dim=6);\n",
    "print(\"BDS Test\")\n",
    "print(\"Dim 2: z-static %.4f Prob %.4f\" % (result[0][0], result[1][0]))\n",
    "print(\"Dim 3: z-static %.4f Prob %.4f\" % (result[0][1], result[1][1]))\n",
    "print(\"Dim 4: z-static %.4f Prob %.4f\" % (result[0][2], result[1][2]))\n",
    "print(\"Dim 5: z-static %.4f Prob %.4f\" % (result[0][3], result[1][3]))\n",
    "print(\"Dim 6: z-static %.4f Prob %.4f\" % (result[0][4], result[1][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Pierce and Ljung-Box tests\n",
    "    Ljung-Box and Box-Pierce statistic differ in their scaling of the autocorrelation function. Ljung-Box test is reported to have better small sample properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLags = 21\n",
    "lbvalue, pvalue, bpvalue, bppvalue = acorr_ljungbox(df_res['resid'].values, lags = range(1, maxLags), boxpierce=True)\n",
    "\n",
    "index = pd.MultiIndex.from_product([range(1, maxLags)], names=['lags'])\n",
    "columns = pd.MultiIndex.from_product([['Box-Pierce', 'Ljung-Box'], ['Stats', 'p-value']], names=['Test', 'Statistics'])\n",
    "data = np.array([bpvalue, bppvalue, lbvalue, pvalue])\n",
    "\n",
    "boxTests = pd.DataFrame(data.T, index=index, columns=columns)\n",
    "boxTests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QQplot\n",
    "    Q-Q plot of the quantiles of x versus the quantiles/ppf of a distribution.\n",
    "    Can take arguments specifying the parameters for dist or fit them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qqplot(df_res['resid'].values, stats.t, fit=True, line='45')\n",
    "plt.title('QQ plot');\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Auto-correlation and Partial Auto-correlation functions\n",
    "    Plots lags on the horizontal and the correlations on vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "# Auto-correlation function\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.grid()\n",
    "sm.graphics.tsa.plot_acf(df_res['resid'].values, lags=maxLags, ax=ax1)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.grid()\n",
    "sm.graphics.tsa.plot_acf(df_res['resid'].values, lags=maxLags, ax=ax2, title = 'Zoom Autocorrelation')\n",
    "ax2.axis((0, maxLags, -0.2, 0.2))\n",
    "\n",
    "# Partial auto-correlation function\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.grid()\n",
    "sm.graphics.tsa.plot_pacf(df_res['resid'].values, lags=maxLags, ax=ax3);\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax4.grid()\n",
    "sm.graphics.tsa.plot_pacf(df_res['resid'].values, lags=maxLags, ax=ax4, title = 'Zoom Partial Autocorrelation')\n",
    "ax4.axis((0, maxLags, -0.2, 0.2));\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(211)\n",
    "plt.title('Real versus Predicted ' + ylab + ' for ' + TS_model) \n",
    "plt.plot(range(0, stepsToForecast[-1]+1), np.concatenate((df_train.values[-1], df_test.values.flatten()), axis=0), 'k-o', linewidth=2)\n",
    "plt.plot(range(1, stepsToForecast[-1]+1), TS_model_forecast, color = cmap(0), linewidth=2)\n",
    "plt.plot([0,1], [df_train.values[-1][0], TS_model_forecast[0]], '--', color = cmap(0), linewidth=2)\n",
    "\n",
    "plt.xlim([0,len(TS_model_forecast)])\n",
    "plt.xticks(np.arange(0, len(TS_model_forecast)+1, step=1))\n",
    "plt.grid(color='k', linestyle='--', linewidth=.5)\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel(ylab)\n",
    "plt.legend(['Real value', 'Predicted value'])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.axhline(y=0, color='k', linestyle='--', linewidth=2)\n",
    "plt.plot(range(0, stepsToForecast[-1]+1), np.concatenate((np.array([0]), df_test.values.flatten()-TS_model_forecast), axis=0), 'g-*', linewidth=2)\n",
    "plt.xticks(np.arange(0, len(TS_model_forecast)+1, step=1))\n",
    "plt.xlim([0,len(TS_model_forecast)])\n",
    "plt.xlabel(xlab)\n",
    "plt.ylabel('Prediction error')\n",
    "plt.grid(color='k', linestyle='--', linewidth=.5)\n",
    "plt.show()\n",
    "\n",
    "print(TS_model)\n",
    "mae  = horizon_mae(df_test.values, TS_model_forecast, stepsToForecast)\n",
    "mape = horizon_mape(df_test.values, TS_model_forecast, stepsToForecast)\n",
    "for i in np.arange(len(stepsToForecast)):\n",
    "    print('Prediction for ' + str(stepsToForecast[i]) + ' ' + xlab + ': MAE = ' \\\n",
    "          + str(round(mae[i], 2)) + ' (' + str(round(mape[i], 2)) + '%)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Forecasted values of ETS model\n",
    "TS_model_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction Overview\n",
    "    Compare: Fitted values of the model with the training data\n",
    "             Predicted values of the model with the testing data\n",
    "      \n",
    "    This section allows to see the forecast of the model that was selected and validated, but also to compare it against other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select from \n",
    "# TS_str = ['TS (N, N)', 'TS (A, N)', 'TS (Ad, N)', \n",
    "#           'TS (N, A)', 'TS (A, A)', 'TS (Ad, A)', \n",
    "#           'TS (N, M)', 'TS (A, M)', 'TS (Ad, M)']\n",
    "TS_labels = ['Train and Test data', \n",
    "             'TS (N, N)',\n",
    "             'TS (A, N)',\n",
    "             'TS (Ad, N)']\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.title('Exponential Smoothing models comparison')\n",
    "plt.plot(1+np.arange(stepsToForecast[-1]), df_test.values, 'k-o' , linewidth = 3, label='Training and testing data')\n",
    "plt.legend(TS_labels, loc='upper left')\n",
    "for i in np.arange(len(TS_labels)-1):\n",
    "    ETS_plot = plt.plot(1+np.arange(stepsToForecast[-1]), TS[TS_str.index(TS_labels[i+1])].forecast(stepsToForecast[-1]), '--*' , linewidth = 3, label = TS_labels[i+1] )\n",
    "    plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, TS[TS_str.index(TS_labels[i+1])].fittedfcast[-previousStepsToShow-1:-1], '--' , linewidth = 3, color=ETS_plot[0].get_color())\n",
    "plt.legend(loc='upper left', framealpha=0.95)\n",
    "plt.plot(1+np.arange(previousStepsToShow)-previousStepsToShow, df_train.values[-previousStepsToShow:], 'k', linewidth = 4 )\n",
    "plt.grid(color='k', linestyle='--', linewidth=.2)\n",
    "plt.xlim([1-previousStepsToShow, stepsToForecast[-1]])\n",
    "plt.xticks(1+np.arange(-previousStepsToShow, stepsToForecast[-1]))\n",
    "plt.xlabel('Past and future samples')\n",
    "plt.ylabel(ylab)\n",
    "plt.show()\n",
    "\n",
    "for i in np.arange(len(TS_labels[1:])):\n",
    "    mae  = horizon_mae(df_test.values, TS[TS_str.index(TS_labels[i+1])].forecast(stepsToForecast[-1]), stepsToForecast)\n",
    "    mape = horizon_mape(df_test.values, TS[TS_str.index(TS_labels[i+1])].forecast(stepsToForecast[-1]), stepsToForecast)\n",
    "    print(TS_labels[i+1])\n",
    "    for i in np.arange(len(stepsToForecast)):\n",
    "        print('Prediction for ' + str(stepsToForecast[i]) + ' ' + xlab + ': MAE = ' \\\n",
    "              + str(round(mae[i], 2)) + ' (' + str(round(mape[i], 2)) + '%)' )\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
